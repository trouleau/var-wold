{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on the dataset Email EU Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import lib\n",
    "from lib.preprocessing import Dataset\n",
    "from lib.models import WoldModelVariational\n",
    "from gb import GrangerBusca\n",
    "\n",
    "# Set cells width for nicer output\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset must first be downloaded from the SNAP dataset repository: <https://snap.stanford.edu/data/email-Eu-core-temporal.html>\n",
    "\n",
    "    wget https://snap.stanford.edu/data/email-Eu-core-temporal.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set input path where the dataset is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"email-Eu-core-temporal.txt.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(INPUT_PATH, top=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(18, 3.5))\n",
    "\n",
    "axs[0].hist(list(map(len, dataset.timestamps)))\n",
    "axs[0].set_xlabel('Number of events \\n in each dim')\n",
    "\n",
    "end_time = dataset.end_time\n",
    "axs[1].hist(list(map(min, dataset.timestamps)), bins=np.linspace(0, end_time, 20))\n",
    "axs[1].set_xlabel('First of event \\n in each dim')\n",
    "\n",
    "axs[2].hist(list(map(max, dataset.timestamps)), bins=np.linspace(0, end_time, 20))\n",
    "axs[2].set_xlabel('Last of events \\n in each dim')\n",
    "\n",
    "fig.suptitle(f\"Dataset {os.path.split(INPUT_PATH)[1]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Num. of dimensions: {len(dataset.timestamps):,d}\")\n",
    "print(f\"    Num. of events: {sum(map(len, dataset.timestamps)):,d}\")\n",
    "print(f\"               %NZ: {100 * dataset.graph.number_of_edges() / (dataset.graph.number_of_nodes() ** 2):.2f}%\")\n",
    "print()\n",
    "print(\"Stats. of num. of events per dim:\")\n",
    "num_jumps_per_dim = np.array(list(map(len, dataset.timestamps)))\n",
    "print(pd.Series(num_jumps_per_dim).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build ground truth adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_true = nx.adjacency_matrix(dataset.graph, nodelist=range(dataset.dim)).toarray()\n",
    "adjacency_true = adjacency_true / adjacency_true.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = dataset.timestamps\n",
    "events = [np.sort(ev) for ev in events]\n",
    "end_time = dataset.end_time\n",
    "\n",
    "t0 = min(map(min, events))\n",
    "t1 = max(map(max, events))\n",
    "\n",
    "train_start = t0\n",
    "train_end = t0 + (t1 - t0) * 0.5\n",
    "test_end = t1 + 1e-5\n",
    "\n",
    "train_events = [ev[(ev >= train_start) & (ev < train_end)] - train_start for ev in events]\n",
    "test_events = [ev[(ev >= train_end) & (ev < test_end)] - train_end for ev in events]\n",
    "\n",
    "print('Number of training events:', sum(map(len, train_events)))\n",
    "print('Number of test events:', sum(map(len, test_events)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the test model to compute the predictive log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dimensions with no observation in the test set\n",
    "test_dims = np.array([len(ev) > 0 for ev in test_events])\n",
    "num_test_events = sum(map(len, test_events))\n",
    "test_events_filtered = np.array(test_events)[test_dims].tolist()\n",
    "# Feed test observations to the model\n",
    "test_model = lib.models.WoldModel()\n",
    "test_model.observe(test_events_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Run VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = len(train_events)\n",
    "\n",
    "# Set priors\n",
    "# prior: Alpha\n",
    "as_pr = 0.1 * np.ones((dim + 1, dim))\n",
    "ar_pr = 1.0 * np.ones((dim + 1, dim))\n",
    "\n",
    "# prior: Beta\n",
    "bs_pr = 101.0 * np.ones((dim, dim))\n",
    "br_pr = 100.0 * np.ones((dim, dim))\n",
    "\n",
    "# prior: Z\n",
    "zc_pr = [1.0 * np.ones((len(train_events[i]), dim+1)) for i in range(dim)]\n",
    "\n",
    "print('ALPHA:')\n",
    "print('------')\n",
    "print('mean')\n",
    "print(as_pr[0,0] / ar_pr[0,0])\n",
    "print('variance')\n",
    "print(as_pr[0,0] / ar_pr[0,0] ** 2)\n",
    "\n",
    "print('BETA:')\n",
    "print('-----')\n",
    "print('mean')\n",
    "print(br_pr[0,0] / (bs_pr[0,0] - 1))\n",
    "print('variance')\n",
    "print(br_pr[0,0]**2 / ((bs_pr[0,0] - 1)**2 * (bs_pr[0,0] - 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model & observations\n",
    "vi_model = WoldModelVariational(verbose=True)\n",
    "vi_model.observe(train_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callback\n",
    "callback = lib.utils.callbacks.Callback(x0=(as_pr[1:,:] / ar_pr[1:,:]).flatten(), \n",
    "                                          print_every=1, dim=dim)\n",
    "\n",
    "# Fit model\n",
    "vi_model.fit(as_pr=as_pr, ar_pr=ar_pr, bs_pr=bs_pr, br_pr=br_pr, zc_pr=zc_pr, \n",
    "             max_iter=100, tol=1e-4, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = list()\n",
    "adj_list = list()\n",
    "for i in range(10):\n",
    "    as_po = vi_model._as_po[np.hstack([[True], test_dims]), :][:, test_dims]\n",
    "    ar_po = vi_model._ar_po[np.hstack([[True], test_dims]), :][:, test_dims]\n",
    "    bs_po = vi_model._bs_po[test_dims, :][:, test_dims]\n",
    "    br_po = vi_model._br_po[test_dims, :][:, test_dims]\n",
    "\n",
    "    alpha_sample = np.random.gamma(shape=as_po, scale=1/ar_po)\n",
    "    beta_sample = np.random.gamma(shape=bs_po, scale=1/br_po)\n",
    "    coeffs = torch.tensor(np.hstack((\n",
    "        alpha_sample[0, :].flatten(), beta_sample.flatten(), alpha_sample[1:, :].flatten()\n",
    "    )))\n",
    "    ll = test_model.log_likelihood(coeffs) / num_test_events\n",
    "    vals.append(ll)\n",
    "    adj_list.append(np.random.gamma(shape=vi_model._as_po, scale=1/vi_model._ar_po)[1:, :])\n",
    "print(f\"Predictive log-likelihood: {np.mean(vals):.2f} ($\\pm {np.std(vals):.2e}$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Run GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = list()\n",
    "for i in range(10):\n",
    "    print(f'\\r{i}', end='')\n",
    "    # Define model\n",
    "    granger_model = GrangerBusca(\n",
    "        alpha_prior=10.00,\n",
    "        num_iter=3000,\n",
    "        metropolis=True,\n",
    "        beta_strategy='busca',\n",
    "        num_jobs=2,\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    granger_model.fit(train_events)\n",
    "\n",
    "    # Extract estimate of parameters\n",
    "    mu_hat = granger_model.mu_[test_dims]\n",
    "    adj_hat = granger_model.Alpha_.toarray()[test_dims, :][:, test_dims]\n",
    "    adj_hat = adj_hat / adj_hat.sum(axis=1)[:, None]\n",
    "    beta_hat = np.ones((len(train_events), len(train_events))) * granger_model.beta_\n",
    "    beta_hat = beta_hat[test_dims, :][:, test_dims]\n",
    "    coeffs_hat = torch.tensor(np.hstack((\n",
    "        mu_hat, beta_hat.flatten(), adj_hat.flatten()\n",
    "    )))\n",
    "\n",
    "    ll = test_model.log_likelihood(coeffs_hat) / num_test_events\n",
    "    vals.append(ll)\n",
    "print(f\"\\nPredictive log-likelihood: {np.mean(vals):.2f} ($\\pm {np.std(vals):.2e}$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
