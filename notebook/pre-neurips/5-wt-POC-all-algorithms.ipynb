{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Variational Inference algorithms for Wold processes\n",
    "\n",
    "In this notebook, we test the various variational inference (VI) algorithms implemented for the multivariate Wold process. Namely:\n",
    "\n",
    "* `WoldModelVariational`: VI with parameters $\\alpha$ and $\\beta$\n",
    "\n",
    "with the **new updates** involving solving a set of 2d^2 1-dimensional equations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load extensions for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries of interest for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set numpy print format\n",
    "np.set_printoptions(precision=2, floatmode='fixed', sign=' ')\n",
    "\n",
    "import tsvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set cells width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set general experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLE_N_ITER = 20000\n",
    "BBVI_N_ITER = 20000\n",
    "VI_FB_N_ITER = 3000\n",
    "VI_N_ITER = 3000\n",
    "GB_N_ITER = 300\n",
    "\n",
    "VI_TOL = 1e-4\n",
    "\n",
    "PRINT_EVERY = 100\n",
    "PRINT_EVERY_VI = 10\n",
    "CALLBACK_END = '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed for all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.randint(2**32-1)\n",
    "gen_seed = None\n",
    "sim_seed = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Generate toy example dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1. Small 2-dimensional toy setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "[ 0.01  0.01]\n",
      "Alpha:\n",
      "[[ 0.70  0.30]\n",
      " [ 0.00  1.00]]\n",
      "Beta:\n",
      "[[ 0.40  0.20]\n",
      " [ 0.50  0.10]]\n"
     ]
    }
   ],
   "source": [
    "# Define random parameters\n",
    "dim = 2  # Dimensionality of the process\n",
    "max_jumps= 25e3 * dim  # Number of events\n",
    "\n",
    "mu = torch.tensor([0.01, 0.01])\n",
    "beta = torch.tensor([\n",
    "    [0.4, 0.2],\n",
    "    [0.5, 0.1]\n",
    "])\n",
    "# Use the same constraint as GrangerBusca to allow fair comparison\n",
    "alpha = torch.tensor([\n",
    "    [0.7, 0.3],\n",
    "    [0.0, 1.0]\n",
    "])\n",
    "\n",
    "print('Baseline:')\n",
    "print(mu.numpy().round(2))\n",
    "print('Alpha:')\n",
    "print(alpha.numpy().round(2))\n",
    "print('Beta:')\n",
    "print(beta.numpy().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2. Larger setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "[ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      "Alpha:\n",
      "[[ 0.18  0.00  0.17  0.19  0.00  0.00  0.00  0.00  0.00  0.11]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.15  0.18  0.12  0.17  0.00]\n",
      " [ 0.14  0.16  0.00  0.00  0.18  0.19  0.00  0.18  0.15  0.11]\n",
      " [ 0.00  0.00  0.00  0.00  0.16  0.00  0.00  0.00  0.00  0.18]\n",
      " [ 0.16  0.00  0.00  0.14  0.00  0.00  0.17  0.11  0.00  0.12]\n",
      " [ 0.15  0.13  0.20  0.00  0.00  0.16  0.11  0.14  0.19  0.00]\n",
      " [ 0.16  0.10  0.00  0.13  0.00  0.00  0.00  0.12  0.00  0.17]\n",
      " [ 0.00  0.14  0.00  0.11  0.11  0.00  0.15  0.11  0.00  0.00]\n",
      " [ 0.15  0.15  0.00  0.13  0.00  0.12  0.16  0.00  0.11  0.00]\n",
      " [ 0.12  0.10  0.10  0.00  0.17  0.00  0.00  0.00  0.17  0.12]]\n",
      "Beta:\n",
      "[[ 0.16  0.50  0.88  0.89  0.72  0.79  0.47  0.85  0.75  0.78]\n",
      " [ 0.48  0.77  0.19  0.85  0.59  0.67  0.39  0.29  0.94  0.33]\n",
      " [ 0.51  0.20  0.31  0.68  0.58  0.87  0.36  0.92  0.02  0.93]\n",
      " [ 0.57  0.29  0.09  0.17  0.93  0.11  0.18  0.78  0.48  0.72]\n",
      " [ 0.92  0.55  0.50  0.62  0.62  0.66  0.80  0.31  0.79  0.88]\n",
      " [ 0.72  0.02  0.61  0.14  0.82  0.11  0.32  0.23  0.43  0.35]\n",
      " [ 0.04  0.05  0.31  0.26  0.82  0.76  0.83  0.31  0.37  0.15]\n",
      " [ 0.39  0.28  0.61  1.00  0.11  0.04  0.88  0.96  0.12  0.33]\n",
      " [ 0.52  0.75  0.59  0.14  0.54  0.62  0.32  0.77  0.54  0.81]\n",
      " [ 0.40  0.65  0.57  0.61  0.77  0.04  0.57  0.74  0.23  0.30]]\n"
     ]
    }
   ],
   "source": [
    "from experiments_utils import generate_parameters\n",
    "\n",
    "dim = 10\n",
    "max_jumps = 10e3 * dim\n",
    "\n",
    "param_dict = generate_parameters(dim=dim, seed=gen_seed, )\n",
    "\n",
    "mu = torch.tensor(param_dict['baseline']) * 0.00\n",
    "beta = torch.tensor(param_dict['beta'])\n",
    "alpha = torch.tensor(param_dict['adjacency'])\n",
    "\n",
    "print('Baseline:')\n",
    "print(mu.numpy().round(2))\n",
    "print('Alpha:')\n",
    "print(alpha.numpy().round(2))\n",
    "print('Beta:')\n",
    "print(beta.numpy().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate a realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Simulate lots of data...\n",
      "    - Simulated 100,000 events with end time: 90853.703125\n",
      "    - Events:\n",
      "      - dim  0 (15709 events): [     0.49      4.34      5.54 ...  90838.49  90844.16  90853.70]\n",
      "      - dim  1 (10852 events): [     0.49      4.00     11.12 ...  90844.99  90846.96  90848.07]\n",
      "      - dim  2 ( 6147 events): [     1.37     18.64     21.79 ...  90798.23  90800.73  90853.18]\n",
      "      - dim  3 (10247 events): [     0.19      1.52      2.59 ...  90837.76  90841.34  90842.16]\n",
      "      - dim  4 ( 7528 events): [     0.18      5.15      8.59 ...  90813.90  90829.66  90835.98]\n",
      "      - dim  5 ( 7199 events): [     1.92      7.46     11.37 ...  90824.81  90844.01  90852.41]\n",
      "      - dim  6 (10334 events): [     1.79      3.84      6.68 ...  90789.75  90831.49  90833.81]\n",
      "      - dim  7 (10117 events): [     2.48      4.60      6.69 ...  90844.28  90845.09  90850.66]\n",
      "      - dim  8 (10521 events): [     1.24      1.66      3.17 ...  90839.51  90851.26  90853.45]\n",
      "      - dim  9 (11346 events): [     3.49     16.97     28.35 ...  90824.25  90840.69  90846.95]\n"
     ]
    }
   ],
   "source": [
    "coeffs_true_dict = {\n",
    "    'baseline': mu.numpy(),\n",
    "    'adjacency': alpha.numpy(),\n",
    "    'beta': beta.numpy()\n",
    "}\n",
    "\n",
    "coeffs_true = torch.cat((mu, beta.flatten(), alpha.flatten())).numpy()\n",
    "print('  - Simulate lots of data...')\n",
    "# Simulate lots of data\n",
    "wold_sim = tsvar.simulate.MultivariateWoldSimulator(\n",
    "    mu_a=mu, alpha_ba=alpha, beta_ba=beta)\n",
    "events = wold_sim.simulate(max_jumps=max_jumps, seed=sim_seed)\n",
    "events = [torch.tensor(ev, dtype=torch.float) for ev in events]\n",
    "end_time = max(map(max, events))\n",
    "print((f\"    - Simulated {sum(map(len, events)):,d} events \"\n",
    "       f\"with end time: {end_time}\"))\n",
    "print(\"    - Events:\")\n",
    "for i, events_i in enumerate(events):\n",
    "    print(f\"      - dim {i:>2d} ({len(events_i):>5d} events):\", events_i.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:   100 | dx: +7.5007e-02 | loss: 6.7859e+00 | dloss: -2.88e-03 | acc: 0.82 | f1-score: 0.82 | relerr: 1.03e+00 | p@5: 0.20 | p@10: 0.10 | p@20: 0.10 | time/it: 4.14e-02     \n",
      "iter:   200 | dx: +5.6126e-02 | loss: 6.6064e+00 | dloss: -1.18e-03 | acc: 0.82 | f1-score: 0.82 | relerr: 1.02e+00 | p@5: 0.20 | p@10: 0.10 | p@20: 0.10 | time/it: 3.57e-02     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-65e856ab2f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                  \u001b[0mlr_sched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMLE_N_ITER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                  \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtsvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianPrior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                  seed=None, callback=callback)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mcoeffs_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoeffs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_wold.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmle_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/utils/decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             raise Exception(('Model is not properly set. '\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/fitter.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, objective_func, x0, optimizer, lr, lr_sched, tol, max_iter, penalty, C, seed, callback)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_iter_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_gradient_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;31m# Check that the optimization did not fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/fitter.py\u001b[0m in \u001b[0;36m_take_gradient_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Gradient update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/utils/decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             raise Exception(('Model is not properly set. '\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_wold.py\u001b[0m in \u001b[0;36mmle_objective\u001b[0;34m(self, coeffs)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmle_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m\"\"\"Objectvie function for MLE: Averaged negative log-likelihood\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jumps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/utils/decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             raise Exception(('Model is not properly set. '\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_wold.py\u001b[0m in \u001b[0;36mlog_likelihood\u001b[0;34m(self, coeffs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                     beta[:, i] + 1 + self.delta_ikj[i]), axis=1)\n\u001b[1;32m    244\u001b[0m             \u001b[0;31m# Add the log-intensity term (ignore the last 'fake' event)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mlog_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlam_ik_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;31m# Subtract the integral term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mlog_like\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlam_ik_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dim = len(events)\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set initial guess\n",
    "coeffs_start = torch.tensor(np.hstack((\n",
    "    np.random.uniform(0.0, 1.0, size=dim),     # baseline\n",
    "    np.random.uniform(0.0, 1.0, size=dim**2),  # beta\n",
    "    np.random.uniform(0.0, 1.0, size=dim**2)   # adjacency\n",
    ")))\n",
    "\n",
    "# Extract ground truth\n",
    "coeffs_true = np.hstack((coeffs_true_dict['baseline'],\n",
    "                         np.array(coeffs_true_dict['beta']).flatten(),\n",
    "                         np.array(coeffs_true_dict['adjacency']).flatten()))\n",
    "\n",
    "# Define model\n",
    "model = tsvar.models.WoldModelMLE(verbose=True)\n",
    "model.observe(events, end_time)\n",
    "\n",
    "# Set callback\n",
    "callback = tsvar.utils.callbacks.LearnerCallbackMLE(\n",
    "    coeffs_start, print_every=PRINT_EVERY, coeffs_true=coeffs_true,\n",
    "    acc_thresh=0.05, dim=dim, default_end=CALLBACK_END)\n",
    "\n",
    "# Fit model\n",
    "conv = model.fit(x0=coeffs_start, optimizer=torch.optim.Adam, lr=0.1,\n",
    "                 lr_sched=0.9999, tol=1e-4, max_iter=MLE_N_ITER,\n",
    "                 penalty=tsvar.priors.GaussianPrior, C=1e10,\n",
    "                 seed=None, callback=callback)\n",
    "coeffs_hat = model.coeffs.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test BBVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:   100 | dx: +9.2621e-04 | loss: 1.8526e+05 | dloss: +1.02e+02 | acc: 0.49 | f1-score: 0.66 | relerr: 9.21e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.97e-02     \n",
      "iter:   200 | dx: +1.3311e-03 | loss: 1.8458e+05 | dloss: +1.29e+02 | acc: 0.49 | f1-score: 0.66 | relerr: 8.51e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.86e-02     \n",
      "iter:   300 | dx: +8.7562e-04 | loss: 1.8412e+05 | dloss: +4.04e+00 | acc: 0.49 | f1-score: 0.66 | relerr: 7.72e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.82e-02     \n",
      "iter:   400 | dx: +1.0891e-03 | loss: 1.8401e+05 | dloss: +8.55e+01 | acc: 0.49 | f1-score: 0.66 | relerr: 7.30e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.87e-02     \n",
      "iter:   500 | dx: +1.2474e-03 | loss: 1.8386e+05 | dloss: -3.52e+01 | acc: 0.49 | f1-score: 0.66 | relerr: 6.87e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.82e-02     \n",
      "iter:   600 | dx: +1.2591e-03 | loss: 1.8376e+05 | dloss: +4.67e+01 | acc: 0.49 | f1-score: 0.66 | relerr: 6.67e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.85e-02     \n",
      "iter:   700 | dx: +8.2606e-04 | loss: 1.8371e+05 | dloss: +6.04e+00 | acc: 0.49 | f1-score: 0.66 | relerr: 6.45e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.90e-02     \n",
      "iter:   800 | dx: +1.1466e-03 | loss: 1.8373e+05 | dloss: +2.71e+01 | acc: 0.50 | f1-score: 0.66 | relerr: 6.24e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.91e-02     \n",
      "iter:   900 | dx: +1.1296e-03 | loss: 1.8369e+05 | dloss: +2.12e+01 | acc: 0.50 | f1-score: 0.66 | relerr: 6.19e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 3.20e-02     \n",
      "iter:  1000 | dx: +8.2013e-04 | loss: 1.8367e+05 | dloss: +2.29e+00 | acc: 0.50 | f1-score: 0.66 | relerr: 6.05e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 3.21e-02     \n",
      "iter:  1100 | dx: +1.1466e-03 | loss: 1.8367e+05 | dloss: +1.38e+01 | acc: 0.50 | f1-score: 0.66 | relerr: 5.96e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 3.14e-02     \n",
      "iter:  1200 | dx: +2.4882e-03 | loss: 1.8363e+05 | dloss: -3.12e+01 | acc: 0.50 | f1-score: 0.66 | relerr: 5.87e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.90e-02     \n",
      "iter:  1300 | dx: +2.1076e-03 | loss: 1.8369e+05 | dloss: +5.75e+01 | acc: 0.51 | f1-score: 0.67 | relerr: 5.88e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 3.38e-02     \n",
      "iter:  1400 | dx: +2.9449e-03 | loss: 1.8367e+05 | dloss: -5.28e+01 | acc: 0.51 | f1-score: 0.67 | relerr: 5.79e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.96e-02     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a91c8b0d46f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m                  \u001b[0mlr_sched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBBVI_N_ITER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                  \u001b[0mmstep_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmstep_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmstep_momentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                  seed=None, callback=callback)\n\u001b[0m",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_wold_bbvi.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbvi_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/utils/decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             raise Exception(('Model is not properly set. '\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/fitter.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, objective_func, x0, optimizer, lr, lr_sched, tol, max_iter, mstep_interval, mstep_offset, mstep_momentum, seed, callback)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_iter_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;31m# E step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0;31m# M step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/fitter.py\u001b[0m in \u001b[0;36m_e_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# Gradient update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/utils/decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             raise Exception(('Model is not properly set. '\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_models.py\u001b[0m in \u001b[0;36mbbvi_objective\u001b[0;34m(self, x, seed)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# Compute a Monte Carlo estimate of the expectation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m  \u001b[0;31m# Negative ELBO (we want to minimize it)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_models.py\u001b[0m in \u001b[0;36m_objective_l\u001b[0;34m(self, eps_l, alpha, beta)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meps_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# Compute the importance weights (and their gradients)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mlog_w_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_importance_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;31m# Temper the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mlog_w_arr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_models.py\u001b[0m in \u001b[0;36m_log_importance_weight\u001b[0;34m(self, eps, alpha, beta)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# Evaluate the log-likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mloglik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Compute the log-prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mlogprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogprior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/utils/decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             raise Exception(('Model is not properly set. '\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_wold.py\u001b[0m in \u001b[0;36mlog_likelihood\u001b[0;34m(self, coeffs)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mlog_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlam_ik_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# Subtract the integral term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mlog_like\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlam_ik_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             log_like -= torch.sum(lam_ik_arr[1:]\n\u001b[1;32m    249\u001b[0m                                   * (self.events[i][1:] - self.events[i][:-1]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dim = len(events)\n",
    "n_params = dim + dim**2 + dim**2\n",
    "# set random seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# Set initial guess\n",
    "coeffs_start = torch.tensor(np.hstack((\n",
    "    # loc\n",
    "    -2.0 * torch.ones(dim, dtype=torch.float),                  # baseline\n",
    "    0.0 * torch.ones((dim, dim), dtype=torch.float).flatten(),  # beta\n",
    "    0.0 * torch.ones((dim, dim), dtype=torch.float).flatten(),  # adjacency\n",
    "    # scale\n",
    "    torch.log(0.2 * torch.ones(dim, dtype=torch.float)),\n",
    "    torch.log(0.2 * torch.ones((dim, dim), dtype=torch.float).flatten()),\n",
    "    torch.log(0.2 * torch.ones((dim, dim), dtype=torch.float).flatten()),\n",
    ")))\n",
    "# Extract ground truth\n",
    "coeffs_true = np.hstack((coeffs_true_dict['baseline'],\n",
    "                         np.array(coeffs_true_dict['beta']).flatten(),\n",
    "                         np.array(coeffs_true_dict['adjacency']).flatten()))\n",
    "\n",
    "# Define priors/posteriors\n",
    "posterior = tsvar.posteriors.LogNormalPosterior\n",
    "prior = tsvar.priors.GaussianLaplacianPrior\n",
    "mask_gaus = torch.zeros(n_params, dtype=torch.bool)\n",
    "mask_gaus[:dim + dim**2] = 1  # Gaussian prior for baseline and beta\n",
    "C = 1e3\n",
    "\n",
    "# Init the model object\n",
    "model = tsvar.models.WoldModelBBVI(posterior=posterior, prior=prior, C=C,\n",
    "                                   prior_kwargs={'mask_gaus': mask_gaus},\n",
    "                                   n_samples=1, n_weights=1, weight_temp=1,\n",
    "                                   verbose=False, device='cpu')\n",
    "model.observe(events, end_time)\n",
    "\n",
    "# Set link function for callback (vi coeffs -> posterior mode)\n",
    "def link_func(coeffs):\n",
    "    \"\"\"variationa coeffs -> posterior mode of adjacency\"\"\"\n",
    "    # Numpy to torch\n",
    "    coeffs = torch.tensor(coeffs) if isinstance(coeffs, np.ndarray) else coeffs\n",
    "    return model.posterior.mode(\n",
    "        coeffs[:model.n_params], coeffs[model.n_params:]\n",
    "    ).detach().numpy()[dim+dim**2:]\n",
    "\n",
    "# Set the callback (callback parameters are posterior mode)\n",
    "callback = tsvar.utils.callbacks.LearnerCallbackMLE(\n",
    "    x0=posterior().mode(\n",
    "        coeffs_start[:dim+2*dim**2], coeffs_start[dim+2*dim**2:]\n",
    "    )[dim+dim**2:],\n",
    "    print_every=PRINT_EVERY,\n",
    "    coeffs_true=coeffs_true,\n",
    "    acc_thresh=0.05,\n",
    "    dim=dim,\n",
    "    link_func=link_func,\n",
    "    default_end=CALLBACK_END)\n",
    "\n",
    "# Fit the model\n",
    "conv = model.fit(x0=coeffs_start, optimizer=torch.optim.Adam, lr=1e-1,\n",
    "                 lr_sched=0.9999, tol=1e-6, max_iter=BBVI_N_ITER,\n",
    "                 mstep_interval=100, mstep_offset=500, mstep_momentum=0.5,\n",
    "                 seed=None, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test VI-fb\n",
    "\n",
    "Algorithm: Mean-Field VI with fixed $\\{\\beta\\}$s using `WoldModelVariationalFixedBeta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:    10 | dx: +8.1321e-03 | acc: 0.82 | f1-score: 0.82 | relerr: 3.10e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.33e-02     \n",
      "iter:    20 | dx: +2.5076e-03 | acc: 0.98 | f1-score: 0.98 | relerr: 1.91e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.31e-02     \n",
      "iter:    30 | dx: +1.5090e-03 | acc: 1.00 | f1-score: 1.00 | relerr: 1.47e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 3.78e-02     \n",
      "iter:    40 | dx: +8.4949e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 1.23e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 3.68e-02     \n",
      "iter:    50 | dx: +4.5760e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 1.08e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.21e-02     \n",
      "iter:    60 | dx: +3.7890e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 9.77e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.25e-02     \n",
      "iter:    70 | dx: +3.1147e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 8.94e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.48e-02     \n",
      "iter:    80 | dx: +2.4975e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 8.26e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 3.48e-02     \n",
      "iter:    90 | dx: +2.0711e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 7.67e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.46e-02     \n",
      "iter:   100 | dx: +1.7500e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 7.17e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.23e-02     \n",
      "iter:   110 | dx: +1.5826e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 6.75e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.35e-02     \n",
      "iter:   120 | dx: +1.4297e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 6.38e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.36e-02     \n",
      "iter:   130 | dx: +1.3490e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 6.07e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.22e-02     \n",
      "iter:   140 | dx: +1.2335e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 5.78e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.20e-02     \n",
      "iter:   150 | dx: +1.1311e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 5.52e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.24e-02     \n",
      "iter:   160 | dx: +1.0575e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 5.29e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.24e-02     \n",
      "iter:   170 | dx: +9.7323e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 5.08e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.32e-02     \n",
      "iter:   180 | dx: +9.0926e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 4.90e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.26e-02     \n",
      "iter:   190 | dx: +8.4692e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 4.74e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.37e-02     \n",
      "iter:   200 | dx: +7.9665e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 4.60e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 4.05e-02     \n",
      "iter:   210 | dx: +7.7927e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 4.49e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.45e-02     \n",
      "iter:   220 | dx: +1.0205e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 4.39e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.45e-02     \n",
      "iter:   230 | dx: +8.4852e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 4.30e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.38e-02     \n",
      "iter:   240 | dx: +9.0692e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 4.22e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.18e-02     \n",
      "iter:   250 | dx: +9.2740e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 4.15e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.32e-02     \n",
      "iter:   260 | dx: +5.4513e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 4.09e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.28e-02     \n",
      "iter:   270 | dx: +5.1593e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 4.04e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.60e-02     \n",
      "iter:   280 | dx: +5.6179e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 4.00e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.27e-02     \n",
      "iter:   290 | dx: +6.5528e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.96e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.55e-02     \n",
      "iter:   300 | dx: +6.8821e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.93e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 3.01e-02     \n",
      "iter:   310 | dx: +8.4039e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.90e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.43e-02     \n",
      "iter:   320 | dx: +5.0406e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.88e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.39e-02     \n",
      "iter:   330 | dx: +5.7275e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.86e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 5.65e-02     \n",
      "iter:   340 | dx: +5.3615e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.84e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 4.44e-02     \n",
      "iter:   350 | dx: +6.2241e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.83e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.89e-02     \n",
      "iter:   360 | dx: +6.5165e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.81e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.44e-02     \n",
      "iter:   370 | dx: +6.2107e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.80e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.35e-02     \n",
      "iter:   380 | dx: +4.6356e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.79e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 3.75e-02     \n",
      "iter:   390 | dx: +3.5487e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.78e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.39e-02     \n",
      "iter:   400 | dx: +4.8466e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.78e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.53e-02     \n",
      "iter:   410 | dx: +5.3207e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.77e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.45e-02     \n",
      "iter:   420 | dx: +3.6582e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.76e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.33e-02     \n",
      "iter:   430 | dx: +4.5442e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.75e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.38e-02     \n",
      "iter:   440 | dx: +5.2959e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.75e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.37e-02     \n",
      "iter:   450 | dx: +4.8539e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.74e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.32e-02     \n",
      "iter:   460 | dx: +3.9671e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.73e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.86e-02     \n",
      "iter:   470 | dx: +2.5806e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.72e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.55e-02     \n",
      "iter:   480 | dx: +3.2535e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.71e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.48e-02     \n",
      "iter:   490 | dx: +4.9266e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.71e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.35e-02     \n",
      "iter:   500 | dx: +4.3790e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.70e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.52e-02     \n",
      "iter:   510 | dx: +4.6335e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.69e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.30e-02     \n",
      "iter:   520 | dx: +2.0854e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.69e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.42e-02     \n",
      "iter:   530 | dx: +5.8345e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.69e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.50e-02     \n",
      "iter:   540 | dx: +4.4950e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.69e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.39e-02     \n",
      "iter:   550 | dx: +3.9722e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.68e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.45e-02     \n",
      "iter:   560 | dx: +4.7238e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.68e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.34e-02     \n",
      "iter:   570 | dx: +6.0768e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.68e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.31e-02     \n",
      "iter:   580 | dx: +3.6756e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.68e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 3.53e-02     \n",
      "iter:   590 | dx: +3.5146e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.68e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.88e-02     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "iter:   600 | dx: +4.0163e-05 | acc: 1.00 | f1-score: 1.00 | relerr: 3.67e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 2.40e-02     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d7d3b66f5a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m conv = model.fit(as_pr=as_pr, ar_pr=ar_pr, zc_pr=zc_pr, max_iter=VI_FB_N_ITER,\n\u001b[0;32m---> 19\u001b[0;31m                  tol=1e-5, callback=callback)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Converged?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/utils/decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             raise Exception(('Model is not properly set. '\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_wold_var_fixed_beta.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, as_pr, ar_pr, zc_pr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzc_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzc_pr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0malpha_posterior_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_po\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_po\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/utils/decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             raise Exception(('Model is not properly set. '\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/fitter.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, step_function, tol, max_iter, seed, callback)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_iter_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# Run iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Sanity check that the optimization did not fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_wold_var_fixed_beta.py\u001b[0m in \u001b[0;36m_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# Update Z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         self._zp_po = _update_z(as_po=self._as_po, ar_po=self._ar_po,\n\u001b[0;32m--> 110\u001b[0;31m                                 D_ikj=self.D_ikj)\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;31m# Set coeffs attribute for Fitter to assess convergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoeffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_po\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ar_po\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dim = len(events)\n",
    "# Extract ground truth\n",
    "coeffs_true = np.hstack((coeffs_true_dict['baseline'],\n",
    "                         coeffs_true_dict['adjacency'].flatten()))\n",
    "# Set model\n",
    "model = tsvar.models.WoldModelVariationalFixedBeta(verbose=True)\n",
    "model.observe(events, beta=coeffs_true_dict['beta'])\n",
    "# Set priors\n",
    "as_pr = 0.1 * np.ones((dim + 1, dim))\n",
    "ar_pr = 1.0 * np.ones((dim + 1, dim))\n",
    "zc_pr = [1.0 * np.ones((len(events[i]), dim+1)) for i in range(dim)]\n",
    "# Set callback (parameters of callback are just the posterior mean of alpha)\n",
    "callback = tsvar.utils.callbacks.LearnerCallbackMLE(\n",
    "    x0=(as_pr / ar_pr).flatten(), print_every=PRINT_EVERY_VI,\n",
    "    coeffs_true=coeffs_true_dict['adjacency'].flatten(),\n",
    "    acc_thresh=0.05, dim=dim, default_end=CALLBACK_END)\n",
    "# Fit model\n",
    "conv = model.fit(as_pr=as_pr, ar_pr=ar_pr, zc_pr=zc_pr, max_iter=VI_FB_N_ITER,\n",
    "                 tol=1e-5, callback=callback)\n",
    "print('Converged?', conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ======================================== WoldModelVariationalFixedBeta ======================================== \n",
      "\n",
      "Baseline:\n",
      "---------\n",
      "Ground truth:\n",
      "[ 0.01  0.03  0.04  0.02  0.03  0.04  0.04  0.01  0.00  0.00]\n",
      "Estimated:\n",
      "[ 0.01  0.02  0.05  0.02  0.03  0.04  0.04  0.01  0.00  0.00]\n",
      "\n",
      "Adjacency:\n",
      "---------\n",
      "Ground truth:\n",
      "[[ 0.00  0.00  0.18  0.11  0.14  0.00  0.00  0.00  0.16  0.12]\n",
      " [ 0.00  0.00  0.13  0.00  0.00  0.12  0.17  0.00  0.15  0.14]\n",
      " [ 0.00  0.15  0.00  0.00  0.13  0.00  0.00  0.00  0.00  0.18]\n",
      " [ 0.14  0.13  0.00  0.10  0.10  0.19  0.00  0.14  0.00  0.12]\n",
      " [ 0.00  0.00  0.00  0.17  0.00  0.14  0.13  0.00  0.00  0.00]\n",
      " [ 0.00  0.10  0.13  0.00  0.00  0.19  0.00  0.00  0.17  0.11]\n",
      " [ 0.00  0.14  0.18  0.00  0.00  0.18  0.00  0.00  0.19  0.00]\n",
      " [ 0.00  0.00  0.17  0.00  0.00  0.00  0.00  0.00  0.00  0.10]\n",
      " [ 0.00  0.11  0.00  0.00  0.13  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 0.00  0.14  0.18  0.15  0.00  0.00  0.00  0.00  0.17  0.18]]\n",
      "Estimated:\n",
      "[[ 0.00  0.00  0.18  0.12  0.15  0.00  0.00  0.00  0.16  0.17]\n",
      " [ 0.00  0.00  0.13  0.00  0.00  0.13  0.16  0.00  0.14  0.14]\n",
      " [ 0.00  0.13  0.00  0.00  0.13  0.00  0.00  0.00  0.00  0.18]\n",
      " [ 0.15  0.12  0.00  0.09  0.11  0.20  0.00  0.15  0.00  0.14]\n",
      " [ 0.00  0.01  0.00  0.18  0.00  0.14  0.13  0.00  0.00  0.00]\n",
      " [ 0.00  0.11  0.10  0.00  0.00  0.17  0.00  0.00  0.16  0.10]\n",
      " [ 0.00  0.14  0.16  0.00  0.00  0.20  0.00  0.00  0.20  0.00]\n",
      " [ 0.00  0.00  0.14  0.00  0.00  0.00  0.00  0.00  0.02  0.09]\n",
      " [ 0.00  0.13  0.00  0.00  0.11  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 0.00  0.12  0.18  0.15  0.01  0.00  0.00  0.00  0.18  0.17]]\n",
      "True Positive: 41\n",
      "True Negative: 59\n",
      "False Positive: 0\n",
      "False Negative: 0\n",
      "F1-Score: 1.0\n",
      "Relatie-Error: 0.03796166126183576\n",
      "\n",
      "Beta:\n",
      "-----\n",
      " -- IS FIXED --\n"
     ]
    }
   ],
   "source": [
    "print('\\n', '='*40, type(model).__name__, '='*40, '\\n')\n",
    "\n",
    "alpha_hat_mean = np.round(model._as_po / model._ar_po, 2)\n",
    "\n",
    "baseline_hat = alpha_hat_mean[0,:]\n",
    "print('Baseline:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(mu.numpy())\n",
    "print('Estimated:')\n",
    "print(baseline_hat)\n",
    "print()\n",
    "\n",
    "adj_true = alpha.numpy()\n",
    "adjacency_hat = alpha_hat_mean[1:,:]\n",
    "print('Adjacency:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(adj_true)\n",
    "print('Estimated:')\n",
    "print(adjacency_hat)\n",
    "\n",
    "THRESH = 0.05\n",
    "fp = tsvar.utils.metrics.false_positive(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "fn = tsvar.utils.metrics.false_negative(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "tp = tsvar.utils.metrics.true_positive(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "tn = tsvar.utils.metrics.true_negative(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "fscore = tsvar.utils.metrics.fscore(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "relerr = tsvar.utils.metrics.relerr(adjacency_hat.flatten(), adj_true.flatten())\n",
    "print('True Positive:', tp)\n",
    "print('True Negative:', tn)\n",
    "print('False Positive:', fp)\n",
    "print('False Negative:', fn)\n",
    "print('F1-Score:', fscore)\n",
    "print('Relatie-Error:', relerr)\n",
    "print()\n",
    "\n",
    "print('Beta:')\n",
    "print('-----')\n",
    "print(' -- IS FIXED --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.grid()\n",
    "plt.boxplot(\n",
    "    [\n",
    "        adjacency_hat[adj_true == 0.0], \n",
    "        adjacency_hat[adj_true > 0.0]\n",
    "    ],\n",
    "    labels=[\n",
    "        'True Non-edges',\n",
    "        'True Edges'\n",
    "    ])\n",
    "plt.ylabel(r'Learned value of paramaters')\n",
    "plt.title('Distribution of learned adjacency weights');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test VI\n",
    "\n",
    "Algorithm: Mean-Field VI with Variable $\\{\\beta\\}$s using `WoldModelVariational`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters of the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:    10 | dx: +3.2485e-03 | acc: 0.95 | f1-score: 0.95 | relerr: 3.28e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.92e-01     \n",
      "iter:    20 | dx: +1.9276e-03 | acc: 1.00 | f1-score: 1.00 | relerr: 2.60e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.45e-01     \n",
      "iter:    30 | dx: +1.4085e-03 | acc: 1.00 | f1-score: 1.00 | relerr: 2.15e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.41e-01     \n",
      "iter:    40 | dx: +1.0855e-03 | acc: 1.00 | f1-score: 1.00 | relerr: 1.81e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.30e-01     \n",
      "iter:    50 | dx: +8.3921e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 1.56e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.31e-01     \n",
      "iter:    60 | dx: +6.4608e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 1.38e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.31e-01     \n",
      "iter:    70 | dx: +5.4085e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 1.23e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.35e-01     \n",
      "iter:    80 | dx: +4.8749e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 1.12e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.39e-01     \n",
      "iter:    90 | dx: +3.9985e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 1.03e-01 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.37e-01     \n",
      "iter:   100 | dx: +3.3595e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 9.54e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.38e-01     \n",
      "iter:   110 | dx: +2.9615e-04 | acc: 1.00 | f1-score: 1.00 | relerr: 8.96e-02 | p@5: 1.00 | p@10: 1.00 | p@20: 1.00 | time/it: 1.57e-01     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-6d82b0beab1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m conv = model.fit(as_pr=as_pr, ar_pr=ar_pr, bs_pr=bs_pr, br_pr=br_pr,\n\u001b[1;32m     24\u001b[0m                  \u001b[0mzc_pr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzc_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVI_N_ITER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVI_TOL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                  callback=callback)\n\u001b[0m",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/utils/decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             raise Exception(('Model is not properly set. '\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_wold_var.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, as_pr, ar_pr, bs_pr, br_pr, zc_pr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbr_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzc_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbr_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzc_pr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0malpha_posterior_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_po\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_po\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/utils/decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             raise Exception(('Model is not properly set. '\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/fitter.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, step_function, tol, max_iter, seed, callback)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_iter_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# Run iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Sanity check that the optimization did not fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/EPFL/research/ongoing/var-wold/tsvar/models/_wold_var.py\u001b[0m in \u001b[0;36m_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mas_po\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_po\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_po\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ar_po\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzp_po\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zp_po\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mbs_pr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bs_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbr_pr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_br_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_ik\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt_ik\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             delta_ikj=self.delta_ikj, valid_mask_ikj=self.valid_mask_ikj)\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# # (debug) Sanity check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dim = len(events)\n",
    "# Set model\n",
    "model = tsvar.models.WoldModelVariational(verbose=True)\n",
    "model.observe(events)\n",
    "# Set priors\n",
    "# prior: Alpha\n",
    "as_pr = 0.1 * np.ones((dim + 1, dim))\n",
    "ar_pr = 1.0 * np.ones((dim + 1, dim))\n",
    "# prior: Beta\n",
    "bs_pr = 10.0 * np.ones((dim, dim))\n",
    "br_pr = 10.0 * np.ones((dim, dim))\n",
    "# prior: Z\n",
    "zc_pr = [1.0 * np.ones((len(events[i]), dim+1)) for i in range(dim)]\n",
    "# Extract ground truth (for callback, only alphas)\n",
    "coeffs_true = coeffs_true_dict['adjacency'].flatten().copy()\n",
    "coeffs_start = (as_pr / ar_pr)[1:, :].flatten()  # start at mean of prior of adjacency (ignore baseline)\n",
    "# Set callback (parameters of callback are just the posterior mean of alpha)\n",
    "callback = tsvar.utils.callbacks.LearnerCallbackMLE(\n",
    "    x0=coeffs_start, print_every=PRINT_EVERY_VI,\n",
    "    coeffs_true=coeffs_true, acc_thresh=0.05, dim=dim,\n",
    "    default_end=CALLBACK_END)\n",
    "# Fit model\n",
    "conv = model.fit(as_pr=as_pr, ar_pr=ar_pr, bs_pr=bs_pr, br_pr=br_pr,\n",
    "                 zc_pr=zc_pr, max_iter=VI_N_ITER, tol=VI_TOL,\n",
    "                 callback=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ======================================== WoldModelVariational ======================================== \n",
      "\n",
      "Baseline:\n",
      "---------\n",
      "Ground truth:\n",
      "[ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      "Estimated:\n",
      "[ 0.01  0.00  0.00  0.01  0.00  0.00  0.01  0.01  0.00  0.01]\n",
      "\n",
      "Adjacency:\n",
      "---------\n",
      "Ground truth:\n",
      "[[ 0.18  0.00  0.17  0.19  0.00  0.00  0.00  0.00  0.00  0.11]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.15  0.18  0.12  0.17  0.00]\n",
      " [ 0.14  0.16  0.00  0.00  0.18  0.19  0.00  0.18  0.15  0.11]\n",
      " [ 0.00  0.00  0.00  0.00  0.16  0.00  0.00  0.00  0.00  0.18]\n",
      " [ 0.16  0.00  0.00  0.14  0.00  0.00  0.17  0.11  0.00  0.12]\n",
      " [ 0.15  0.13  0.20  0.00  0.00  0.16  0.11  0.14  0.19  0.00]\n",
      " [ 0.16  0.10  0.00  0.13  0.00  0.00  0.00  0.12  0.00  0.17]\n",
      " [ 0.00  0.14  0.00  0.11  0.11  0.00  0.15  0.11  0.00  0.00]\n",
      " [ 0.15  0.15  0.00  0.13  0.00  0.12  0.16  0.00  0.11  0.00]\n",
      " [ 0.12  0.10  0.10  0.00  0.17  0.00  0.00  0.00  0.17  0.12]]\n",
      "Estimated:\n",
      "[[ 0.15  0.01  0.14  0.13  0.01  0.00  0.01  0.01  0.00  0.08]\n",
      " [ 0.01  0.01  0.00  0.01  0.01  0.11  0.15  0.12  0.13  0.01]\n",
      " [ 0.13  0.17  0.01  0.00  0.15  0.17  0.01  0.13  0.16  0.07]\n",
      " [ 0.02  0.01  0.00  0.01  0.10  0.01  0.01  0.01  0.01  0.14]\n",
      " [ 0.12  0.01  0.00  0.10  0.01  0.00  0.14  0.09  0.01  0.09]\n",
      " [ 0.16  0.10  0.17  0.01  0.00  0.15  0.08  0.15  0.16  0.01]\n",
      " [ 0.13  0.10  0.01  0.13  0.00  0.00  0.01  0.08  0.01  0.15]\n",
      " [ 0.02  0.10  0.00  0.07  0.10  0.00  0.09  0.09  0.01  0.01]\n",
      " [ 0.11  0.12  0.00  0.11  0.01  0.10  0.14  0.01  0.09  0.01]\n",
      " [ 0.11  0.08  0.07  0.00  0.13  0.00  0.01  0.01  0.15  0.11]]\n",
      "True Positive: 51\n",
      "True Negative: 49\n",
      "False Positive: 0\n",
      "False Negative: 0\n",
      "F1-Score: 1.0\n",
      "Relatie-Error: 0.12596345868467423\n",
      "\n",
      "Beta:\n",
      "-----\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print('\\n', '='*40, type(model).__name__, '='*40, '\\n')\n",
    "\n",
    "alpha_hat_mean = model._as_po / model._ar_po\n",
    "\n",
    "baseline_hat = alpha_hat_mean[0,:]\n",
    "print('Baseline:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(mu.numpy())\n",
    "print('Estimated:')\n",
    "print(baseline_hat)\n",
    "print()\n",
    "\n",
    "adj_true = alpha.numpy()\n",
    "adjacency_hat = alpha_hat_mean[1:,:]\n",
    "print('Adjacency:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(adj_true)\n",
    "print('Estimated:')\n",
    "print(adjacency_hat)\n",
    "\n",
    "THRESH = 0.05\n",
    "fp = tsvar.utils.metrics.false_positive(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "fn = tsvar.utils.metrics.false_negative(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "tp = tsvar.utils.metrics.true_positive(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "tn = tsvar.utils.metrics.true_negative(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "fscore = tsvar.utils.metrics.fscore(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "relerr = tsvar.utils.metrics.relerr(adjacency_hat.flatten(), adj_true.flatten())\n",
    "print('True Positive:', tp)\n",
    "print('True Negative:', tn)\n",
    "print('False Positive:', fp)\n",
    "print('False Negative:', fn)\n",
    "print('F1-Score:', fscore)\n",
    "print('Relatie-Error:', relerr)\n",
    "print()\n",
    "\n",
    "print('Beta:')\n",
    "print('-----')\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gb\n",
    "import time\n",
    "\n",
    "dim = len(events)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "GB_N_ITER = 300\n",
    "\n",
    "# Define model\n",
    "granger_model = gb.GrangerBusca(\n",
    "    alpha_prior=1.0/len(events),\n",
    "    num_iter=GB_N_ITER,\n",
    "    metropolis=True,\n",
    "    beta_strategy='busca',\n",
    "    num_jobs=1,\n",
    ")\n",
    "start_time = time.time()\n",
    "granger_model.fit(events)\n",
    "run_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "---------\n",
      "Ground truth:\n",
      "[ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      "Estimated:\n",
      "[ 0.01  0.00  0.00  0.01  0.00  0.00  0.01  0.01  0.00  0.01]\n",
      "\n",
      "Adjacency:\n",
      "---------\n",
      "Ground truth:\n",
      "[[ 0.18  0.00  0.17  0.19  0.00  0.00  0.00  0.00  0.00  0.11]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.15  0.18  0.12  0.17  0.00]\n",
      " [ 0.14  0.16  0.00  0.00  0.18  0.19  0.00  0.18  0.15  0.11]\n",
      " [ 0.00  0.00  0.00  0.00  0.16  0.00  0.00  0.00  0.00  0.18]\n",
      " [ 0.16  0.00  0.00  0.14  0.00  0.00  0.17  0.11  0.00  0.12]\n",
      " [ 0.15  0.13  0.20  0.00  0.00  0.16  0.11  0.14  0.19  0.00]\n",
      " [ 0.16  0.10  0.00  0.13  0.00  0.00  0.00  0.12  0.00  0.17]\n",
      " [ 0.00  0.14  0.00  0.11  0.11  0.00  0.15  0.11  0.00  0.00]\n",
      " [ 0.15  0.15  0.00  0.13  0.00  0.12  0.16  0.00  0.11  0.00]\n",
      " [ 0.12  0.10  0.10  0.00  0.17  0.00  0.00  0.00  0.17  0.12]]\n",
      "Estimated:\n",
      "[[ 0.67  0.00  0.21  0.22  0.01  0.00  0.00  0.00  0.00  0.02]\n",
      " [ 0.00  0.39  0.00  0.00  0.00  0.16  0.28  0.08  0.11  0.00]\n",
      " [ 0.12  0.08  0.32  0.00  0.09  0.04  0.00  0.11  0.08  0.00]\n",
      " [ 0.00  0.00  0.00  0.54  0.12  0.00  0.00  0.01  0.00  0.32]\n",
      " [ 0.18  0.00  0.00  0.03  0.39  0.00  0.14  0.06  0.00  0.08]\n",
      " [ 0.01  0.15  0.12  0.00  0.00  0.45  0.01  0.15  0.06  0.00]\n",
      " [ 0.13  0.12  0.00  0.14  0.00  0.00  0.27  0.10  0.00  0.20]\n",
      " [ 0.00  0.27  0.00  0.04  0.11  0.00  0.10  0.49  0.00  0.00]\n",
      " [ 0.00  0.02  0.00  0.05  0.00  0.17  0.21  0.00  0.58  0.00]\n",
      " [ 0.15  0.00  0.13  0.00  0.13  0.00  0.00  0.00  0.18  0.44]]\n",
      "True Positive: 41\n",
      "True Negative: 44\n",
      "False Positive: 5\n",
      "False Negative: 10\n",
      "F1-Score: 0.845360824742268\n",
      "Relatie-Error: 0.542340488541491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adj_true = alpha.numpy()\n",
    "\n",
    "# Extract infered adjacency\n",
    "adj_hat = granger_model.Alpha_.toarray()\n",
    "adj_hat = adj_hat / adj_hat.sum(axis=1)\n",
    "beta_hat = np.ones((dim, dim)) * (granger_model.beta_ + 1)\n",
    "coeffs_hat = np.hstack((granger_model.mu_, beta_hat.flatten(),\n",
    "                        adj_hat.flatten()))\n",
    "\n",
    "baseline_hat = alpha_hat_mean[0,:]\n",
    "print('Baseline:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(mu.numpy())\n",
    "print('Estimated:')\n",
    "print(baseline_hat)\n",
    "print()\n",
    "\n",
    "adj_true = alpha.numpy()\n",
    "adjacency_hat = adj_hat\n",
    "print('Adjacency:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(adj_true)\n",
    "print('Estimated:')\n",
    "print(adjacency_hat)\n",
    "\n",
    "THRESH = 0.05\n",
    "fp = tsvar.utils.metrics.false_positive(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "fn = tsvar.utils.metrics.false_negative(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "tp = tsvar.utils.metrics.true_positive(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "tn = tsvar.utils.metrics.true_negative(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "fscore = tsvar.utils.metrics.fscore(adjacency_hat.flatten(), adj_true.flatten(), threshold=THRESH)\n",
    "relerr = tsvar.utils.metrics.relerr(adjacency_hat.flatten(), adj_true.flatten())\n",
    "print('True Positive:', tp)\n",
    "print('True Negative:', tn)\n",
    "print('False Positive:', fp)\n",
    "print('False Negative:', fn)\n",
    "print('F1-Score:', fscore)\n",
    "print('Relatie-Error:', relerr)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.grid()\n",
    "plt.boxplot(\n",
    "    [\n",
    "        adj_hat[adj_true == 0.0], \n",
    "        adj_hat[adj_true > 0.0]\n",
    "    ],\n",
    "    labels=[\n",
    "        'True Non-edges',\n",
    "        'True Edges'\n",
    "    ])\n",
    "plt.ylabel(r'Learned value of paramaters')\n",
    "plt.title('Distribution of learned adjacency weights');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check variation accross runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Diff with last call:')\n",
    "print('sum:', np.sum(np.abs(adj_hat - last_adj)))\n",
    "print('max:', np.max(np.abs(adj_hat - last_adj)))\n",
    "print('# diff edges:', np.sum((adj_hat > 0.05) ^ (last_adj > 0.05)))\n",
    "last_adj = adj_hat.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
