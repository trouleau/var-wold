{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "import gb\n",
    "\n",
    "import tsvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Simulation \n",
    "\n",
    "Define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.tensor([0.1, 0.1, 0.1, 0.1])\n",
    "\n",
    "beta = torch.tensor([1.1, 1.1, 1.1, 1.1])\n",
    "\n",
    "alpha = torch.tensor([\n",
    "    [0.7, 0.7, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.7],\n",
    "    [0.0, 0.7, 0.7, 0.0]\n",
    "])\n",
    "\n",
    "\n",
    "dim = 4\n",
    "n_params = len(mu) + len(beta) + len(alpha.flatten())\n",
    "\n",
    "coeffs_true = torch.cat((mu, beta, alpha.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tsvar.simulate' has no attribute 'GrangeBuscaSimulator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-74eaa14a8fee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwold_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGrangeBuscaSimulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_rates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlpha_ba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBeta_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwold_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mevents_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mev\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tsvar.simulate' has no attribute 'GrangeBuscaSimulator'"
     ]
    }
   ],
   "source": [
    "end_time = 500000.0\n",
    "\n",
    "wold_sim = tsvar.simulate.GrangeBuscaSimulator(mu_rates=mu, Alpha_ba=alpha, Beta_b=beta)\n",
    "events = wold_sim.simulate(end_time)\n",
    "events_t = [torch.tensor(ev, dtype=torch.float) for ev in events]\n",
    "\n",
    "print(f\"Simulated {sum(map(len, events_t))} events with end time: {end_time}\")\n",
    "print(list(map(len, events_t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. GrangerBusca\n",
    "\n",
    "Run the GrangerBusca algorithm based on Gibbs sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3165, 1: 2828, 2: 1970, 3: 1447}\n",
      "{0: array([2], dtype=uint64), 1: array([1], dtype=uint64), 2: array([3], dtype=uint64), 3: array([0], dtype=uint64)}\n",
      "\n",
      "Mu:\n",
      "[0.12 0.24 0.27 0.17]\n",
      "Beta:\n",
      "[1. 1. 1. 1.]\n",
      "Alpha:\n",
      "[[0.64 0.75 0.   0.15]\n",
      " [0.23 0.54 0.8  0.13]\n",
      " [0.18 0.01 0.55 0.81]\n",
      " [0.   0.71 0.69 0.15]]\n"
     ]
    }
   ],
   "source": [
    "granger_model = gb.GrangerBusca(\n",
    "    alpha_prior=0.1, num_iter=2000,\n",
    "    metropolis=False, sloppy=1, beta_strategy=1.0)\n",
    "granger_model.fit(events);\n",
    "\n",
    "print()\n",
    "print('Mu:')\n",
    "print(granger_model.mu_.round(2))\n",
    "print('Beta:')\n",
    "print(granger_model.beta_.round(2))\n",
    "print('Alpha:')\n",
    "print(sklearn.preprocessing.normalize(granger_model.Alpha_.toarray()).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7, 0.7, 0. , 0. ],\n",
       "       [0. , 0. , 0.7, 0. ],\n",
       "       [0. , 0. , 0. , 0.7],\n",
       "       [0. , 0.7, 0.7, 0. ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.numpy().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Run BBVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 10000 | dx: 3.5862e-03 | loss: 1.5441e+04    "
     ]
    }
   ],
   "source": [
    "x0 = torch.cat((\n",
    "    2.0 * torch.ones(dim, dtype=torch.float),\n",
    "    3.0 * torch.ones(dim, dtype=torch.float),\n",
    "    0.5 * torch.ones((dim, dim), dtype=torch.float).flatten()\n",
    "))\n",
    " \n",
    "optimizer = torch.optim.Adam([x0], lr=0.03)\n",
    "\n",
    "learner_mle = tsvar.learners.MLELearner(\n",
    "    model=tsvar.wold_model.WoldModel(), \n",
    "    prior=tsvar.priors.GaussianLaplacianPrior(\n",
    "        C=torch.ones(n_params, dtype=torch.float) * 100.0,\n",
    "        mask_gaus=torch.cat((\n",
    "            torch.ones(2 * dim, dtype=torch.bool),\n",
    "            torch.zeros(dim * dim, dtype=torch.bool)\n",
    "        ))\n",
    "    ),\n",
    "    optimizer=optimizer, tol=1e-5, max_iter=10000, debug=False)\n",
    "\n",
    "learner_callback_mle = tsvar.utils.callbacks.LearnerCallbackMLE(x0, coeffs_true.numpy(), print_every=100)\n",
    "\n",
    "coeffs_hat_mle = learner_mle.fit(events_t, end_time, x0, callback=learner_callback_mle).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE estimation:\n",
      "mu:\n",
      "[0.08 0.09 0.06 0.11]\n",
      "beta:\n",
      "[1.24 1.12 1.01 1.06]\n",
      "alpha:\n",
      "[[0.77 0.8  0.02 0.03]\n",
      " [0.   0.01 0.71 0.01]\n",
      " [0.01 0.02 0.05 0.67]\n",
      " [0.06 0.67 0.68 0.  ]]\n",
      "\n",
      "Ground truth:\n",
      "mu:\n",
      "[0.1 0.1 0.1 0.1]\n",
      "beta:\n",
      "[1.1 1.1 1.1 1.1]\n",
      "alpha:\n",
      "[[0.7 0.7 0.  0. ]\n",
      " [0.  0.  0.7 0. ]\n",
      " [0.  0.  0.  0.7]\n",
      " [0.  0.7 0.7 0. ]]\n"
     ]
    }
   ],
   "source": [
    "print('MLE estimation:')\n",
    "print('mu:')\n",
    "print(coeffs_hat_mle[:dim].round(2))\n",
    "print('beta:')\n",
    "print(1 + coeffs_hat_mle[dim:2*dim].round(2))\n",
    "print('alpha:')\n",
    "print(np.reshape(coeffs_hat_mle[2*dim:], (dim, dim)).round(2))\n",
    "print()\n",
    "print('Ground truth:')\n",
    "print('mu:')\n",
    "print(coeffs_true[:dim].numpy().round(2))\n",
    "print('beta:')\n",
    "print(coeffs_true[dim:2*dim].numpy().round(2))\n",
    "print('alpha:')\n",
    "print(np.reshape(coeffs_true[2*dim:], (dim, dim)).numpy().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- x0:\n",
      "alpha0: tensor([ 0.1150,  0.0137,  0.1406,  0.1430,  0.1756,  0.0426,  0.0099, -0.1360,\n",
      "         0.1301,  0.1368,  0.2858,  0.0255, -0.1056,  0.0451,  0.1138,  0.0924,\n",
      "         0.0922,  0.0919,  0.1142,  0.1587,  0.2003,  0.0498,  0.2511,  0.3000])\n",
      "beta0: tensor([-11.4825, -11.4916, -11.4771, -11.6889, -11.6135, -11.6036, -11.4957,\n",
      "        -11.5414, -11.3675, -11.3810, -11.6354, -11.6472, -11.4665, -11.4827,\n",
      "        -11.4458, -11.3644, -11.4595, -11.3844, -11.5981, -11.4948, -11.6035,\n",
      "        -11.4157, -11.8216, -11.6248])\n",
      "\n",
      "iter:  5000 | dx: 5.8867e-03 | loss: 1.5676e+04    "
     ]
    }
   ],
   "source": [
    "from tsvar.wold_model import WoldModel\n",
    "from tsvar.models import ModelVariational\n",
    "from tsvar.priors import GaussianLaplacianPrior\n",
    "from tsvar.posteriors import LogNormalPosterior\n",
    "from tsvar.learners import VariationalInferenceLearner\n",
    "\n",
    "# model_wold = WoldModelSimple()\n",
    "# model_wold.set_beta(beta)\n",
    "# n_params = len(mu) + len(A.flatten())\n",
    "\n",
    "model_wold = WoldModel()\n",
    "n_params = len(mu) + len(beta) + len(alpha.flatten())\n",
    "\n",
    "model_var = ModelVariational(\n",
    "    model=model_wold,\n",
    "    prior=GaussianLaplacianPrior(\n",
    "        C=torch.ones(n_params, dtype=torch.float) * 10.0,\n",
    "        mask_gaus=torch.cat((\n",
    "            torch.ones(dim, dtype=torch.bool),\n",
    "            torch.zeros(dim + dim * dim, dtype=torch.bool)\n",
    "        ))\n",
    "    ),\n",
    "    posterior=LogNormalPosterior(),\n",
    "    n_samples=1,\n",
    ")\n",
    "\n",
    "coeffs_true = torch.cat((mu, beta, alpha.flatten()))\n",
    "\n",
    "x0 = torch.tensor(np.hstack((\n",
    "    np.random.normal(loc=0.1, scale=0.1, size=dim),\n",
    "    np.random.normal(loc=0.1, scale=0.1, size=dim),\n",
    "    np.random.normal(loc=0.1, scale=0.1, size=dim*dim),\n",
    "    \n",
    "    np.log(np.random.normal(loc=1e-5, scale=0.000001, size=dim)),\n",
    "    np.log(np.random.normal(loc=1e-5, scale=0.000001, size=dim)),\n",
    "    np.log(np.random.normal(loc=1e-5, scale=0.000001, size=dim*dim)),\n",
    ")), dtype=torch.float)\n",
    "\n",
    "print('--------- x0:')\n",
    "print('alpha0:', x0[:n_params])\n",
    "print('beta0:', x0[n_params:])\n",
    "print()\n",
    "\n",
    "optimizer = torch.optim.Adagrad([x0])\n",
    "\n",
    "learner_callback = tsvar.utils.callbacks.LearnerCallbackMLE(x0, coeffs_true.numpy(), print_every=100)\n",
    "\n",
    "learner = VariationalInferenceLearner(\n",
    "    model=model_var, optimizer=optimizer, lr=0.1,\n",
    "    tol=1e-6, \n",
    "    lr_gamma=0.9999, max_iter=5000,\n",
    "    hyperparam_interval=1000, hyperparam_offset=np.inf, hyperparam_momentum=0.0,\n",
    ")\n",
    "\n",
    "coeffs_hat_vi = learner.fit(events_t, end_time, x0, callback=learner_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== VI estimation:\n",
      "--- mu:\n",
      "mode:\n",
      "[0.11 0.18 0.28 0.18]\n",
      "std:\n",
      "[0. 0. 0. 0.]\n",
      "--- beta:\n",
      "mode:\n",
      "[3.05 5.27 4.89 3.2 ]\n",
      "std:\n",
      "[0.66 2.16 1.22 0.55]\n",
      "--- alpha:\n",
      "mode:\n",
      "[[0.53 0.67 0.34 0.22]\n",
      " [0.17 0.34 0.5  0.22]\n",
      " [0.17 0.29 0.36 0.4 ]\n",
      " [0.17 0.89 0.8  0.31]]\n",
      "std:\n",
      "[[0.17 0.2  0.1  0.  ]\n",
      " [0.   0.1  0.14 0.1 ]\n",
      " [0.   0.1  0.1  0.1 ]\n",
      " [0.   0.14 0.2  0.1 ]]\n",
      "\n",
      "==== Ground truth:\n",
      "mu:\n",
      "[0.1 0.1 0.1 0.1]\n",
      "beta:\n",
      "[1.1 1.1 1.1 1.1]\n",
      "alpha:\n",
      "[[0.7 0.7 0.  0. ]\n",
      " [0.  0.  0.7 0. ]\n",
      " [0.  0.  0.  0.7]\n",
      " [0.  0.7 0.7 0. ]]\n"
     ]
    }
   ],
   "source": [
    "coeffs_hat_vi_mode = learner.model.posterior.mode(coeffs_hat[:n_params], coeffs_hat[n_params:]).detach().numpy().round(2)\n",
    "coeffs_hat_vi_std = np.sqrt(learner.model.posterior.variance(coeffs_hat[:n_params], coeffs_hat[n_params:]).detach().numpy().round(2))\n",
    "\n",
    "\n",
    "print('==== VI estimation:')\n",
    "print('--- mu:')\n",
    "print('mode:')\n",
    "print(coeffs_hat_vi_mode[:dim].round(2))\n",
    "print('std:')\n",
    "print(coeffs_hat_vi_std[:dim].round(2))\n",
    "print('--- beta:')\n",
    "print('mode:')\n",
    "print(1 + coeffs_hat_vi_mode[dim:2*dim].round(2))\n",
    "print('std:')\n",
    "print(coeffs_hat_vi_std[dim:2*dim].round(2))\n",
    "print('--- alpha:')\n",
    "print('mode:')\n",
    "print(np.reshape(coeffs_hat_vi_mode[2*dim:], (dim, dim)).round(2))\n",
    "print('std:')\n",
    "print(np.reshape(coeffs_hat_vi_std[2*dim:], (dim, dim)).round(2))\n",
    "print()\n",
    "print('==== Ground truth:')\n",
    "print('mu:')\n",
    "print(coeffs_true[:dim].numpy().round(2))\n",
    "print('beta:')\n",
    "print(coeffs_true[dim:2*dim].numpy().round(2))\n",
    "print('alpha:')\n",
    "print(np.reshape(coeffs_true[2*dim:], (dim, dim)).numpy().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
