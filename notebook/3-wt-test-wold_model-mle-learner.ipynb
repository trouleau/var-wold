{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import tsvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.tensor([0.2, 0.1])\n",
    "beta = torch.tensor([1.1, 1.5])\n",
    "A = torch.tensor([\n",
    "    [0.7, 0.3],\n",
    "    [0.1, 0.9]\n",
    "])\n",
    "dim = 2\n",
    "\n",
    "#coeffs = torch.cat((mu, beta[0], A.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 102680 events with end time: 100000.0\n",
      "[50859, 51821]\n"
     ]
    }
   ],
   "source": [
    "end_time = 100000.0\n",
    "\n",
    "wold_sim = tsvar.simulate.GrangeBuscaSimulator(mu_rates=mu, Alpha_ba=A, Beta_b=beta)\n",
    "events = wold_sim.simulate(end_time)\n",
    "events = [torch.tensor(ev, dtype=torch.float) for ev in events]\n",
    "\n",
    "print(f\"Simulated {sum(map(len, events))} events with end time: {end_time}\")\n",
    "print(list(map(len, events)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WoldModelSimple(tsvar.wold_model.WoldModel):\n",
    "    \n",
    "    def set_data(self, events, end_time=None):\n",
    "        super().set_data(events, end_time)\n",
    "        self.n_params = self.dim * (self.dim - 1) + self.dim\n",
    "\n",
    "    def log_likelihood(self, coeffs):\n",
    "        # Extract each set of parameters\n",
    "        mu = coeffs[:self.dim]\n",
    "        beta = coeffs[self.dim:2*self.dim]\n",
    "        alpha = coeffs[2*self.dim:].reshape(self.dim, self.dim)\n",
    "        # Compute the log-likelihood\n",
    "        log_like = 0\n",
    "        for i in range(self.dim):\n",
    "            # Compute the intensity at each event\n",
    "            lam_ik_arr = mu[i] + torch.sum(\n",
    "                self.valid_mask_ikj[i] * alpha[:,i] /(beta.unsqueeze(0) + self.delta_ikj[i]), \n",
    "                axis=1)\n",
    "            # Add the log-intensity term\n",
    "            log_like += lam_ik_arr[:-1].log().sum()\n",
    "            # Subtract the integral term\n",
    "            log_like -= lam_ik_arr[0] * self.events[i][0]\n",
    "            log_like -= torch.sum(lam_ik_arr[1:] * (self.events[i][1:] - self.events[i][:-1]))\n",
    "        return log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tsvar.wold_model.WoldModel()\n",
    "model.set_data(events, end_time)\n",
    "\n",
    "coeffs_true = torch.cat((mu, beta - 1, A.flatten()))\n",
    "\n",
    "x0 = torch.cat((\n",
    "    0.01 * torch.ones(dim, dtype=torch.float),\n",
    "    1.0 * torch.ones(dim, dtype=torch.float),\n",
    "    0.5 * torch.ones((dim, dim), dtype=torch.float).flatten()\n",
    "))\n",
    "\n",
    "C = 1000.0 * torch.ones(len(coeffs_true))\n",
    "prior = tsvar.priors.GaussianPrior(C=C)\n",
    "\n",
    "optimizer = torch.optim.Adam([x0], lr=0.5)\n",
    "\n",
    "learner = tsvar.learners.MLELearner(\n",
    "    model=model, \n",
    "    prior=prior, \n",
    "    optimizer=optimizer,\n",
    "    tol=1e-5,\n",
    "    max_iter=100000,\n",
    "    debug=False)\n",
    "\n",
    "learner_callback = tsvar.utils.callbacks.LearnerCallbackMLE(x0, coeffs_true.numpy(), print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2000, 0.1000, 0.1000, 0.5000, 0.7000, 0.3000, 0.1000, 0.9000])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0100, 0.0100, 1.0000, 1.0000, 0.5000, 0.5000, 0.5000, 0.5000])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:   400 | dx: 1.3173e-05 | loss: 1.6653e+05    loss = 166531.28125 Converged!\n"
     ]
    }
   ],
   "source": [
    "coeffs_hat = learner.fit(events, end_time, x0, callback=learner_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21, 0.1 , 0.08, 0.26, 0.69, 0.31, 0.07, 0.78], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_hat.detach().numpy().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.1, 0.1, 0.5, 0.7, 0.3, 0.1, 0.9], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_true.detach().numpy().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(181507.1562)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-model.log_likelihood(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(166531.2812, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-model.log_likelihood(coeffs_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(166539.1875)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-model.log_likelihood(coeffs_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
