{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import tsvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.tensor([0.05, 0.1, 0.05, 0.05])\n",
    "\n",
    "beta = torch.tensor([1.5, 1.5, 1.0, 1.0])\n",
    "\n",
    "alpha = torch.tensor([\n",
    "    [0.7, 0.7, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.7],\n",
    "    [0.0, 0.7, 0.7, 0.0]\n",
    "])\n",
    "\n",
    "\n",
    "dim = 4\n",
    "# n_params = len(mu) + len(beta) + len(A.flatten())\n",
    "\n",
    "coeffs_true = torch.cat((mu, beta, alpha.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 66909 events with end time: 50000.0\n",
      "[8768, 21995, 23228, 12918]\n"
     ]
    }
   ],
   "source": [
    "end_time = 50000.0\n",
    "\n",
    "wold_sim = tsvar.simulate.GrangeBuscaSimulator(mu_rates=mu, Alpha_ba=alpha, Beta_b=beta)\n",
    "events = wold_sim.simulate(end_time)\n",
    "events = [torch.tensor(ev, dtype=torch.float) for ev in events]\n",
    "\n",
    "print(f\"Simulated {sum(map(len, events))} events with end time: {end_time}\")\n",
    "print(list(map(len, events)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_true = torch.cat((mu, beta, A.flatten()))\n",
    "\n",
    "x0 = torch.cat((\n",
    "    2.0 * torch.ones(dim, dtype=torch.float),\n",
    "    3.0 * torch.ones(dim, dtype=torch.float),\n",
    "    0.5 * torch.ones((dim, dim), dtype=torch.float).flatten()\n",
    "))\n",
    " \n",
    "optimizer = torch.optim.Adam([x0], lr=0.03)\n",
    "\n",
    "learner_mle = tsvar.learners.MLELearner(\n",
    "    model=tsvar.wold_model.WoldModel(), \n",
    "    prior=tsvar.priors.GaussianPrior(\n",
    "        C=100.0 * torch.ones(len(coeffs_true))), \n",
    "    optimizer=optimizer, tol=1e-5, max_iter=10000, debug=False)\n",
    "\n",
    "learner_callback_mle = tsvar.utils.callbacks.LearnerCallbackMLE(x0, coeffs_true.numpy(), print_every=10)\n",
    "\n",
    "coeffs_hat_mle = learner_mle.fit(events, end_time, x0, callback=learner_callback_mle).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ground truth:')\n",
    "print('mu:')\n",
    "print(coeffs_true[:dim].numpy().round(2))\n",
    "print('beta:')\n",
    "print(coeffs_true[dim:2*dim].numpy().round(2))\n",
    "print('alpha:')\n",
    "print(np.reshape(coeffs_true[2*dim:], (dim, dim)).numpy().round(2))\n",
    "print()\n",
    "print('MLE estimation:')\n",
    "print('mu:')\n",
    "print(coeffs_hat_mle[:dim].round(2))\n",
    "print('beta:')\n",
    "print(coeffs_hat_mle[dim:2*dim].round(2))\n",
    "print('alpha:')\n",
    "print(np.reshape(coeffs_hat_mle[2*dim:], (dim, dim)).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run BBVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsvar.wold_model import WoldModel\n",
    "\n",
    "class WoldModelSimple(WoldModel):\n",
    "    \n",
    "    def set_beta(self, beta_b):\n",
    "        self.beta = beta_b\n",
    "        \n",
    "    def set_data(self, events, end_time=None):\n",
    "        super().set_data(events, end_time)\n",
    "        self.n_params = self.dim * self.dim + self.dim\n",
    "    \n",
    "    def log_likelihood(self, coeffs):\n",
    "        # Extract each set of parameters\n",
    "        mu = coeffs[:self.dim]\n",
    "        alpha = coeffs[self.dim:].reshape(self.dim, self.dim)\n",
    "        # Compute the log-likelihood\n",
    "        log_like = 0\n",
    "        for i in range(self.dim):\n",
    "            # Compute the intensity at each event\n",
    "            lam_ik_arr = mu[i] + torch.sum(self.valid_mask_ikj[i] * alpha[:,i] /(self.beta.unsqueeze(0) + self.delta_ikj[i]), axis=1)\n",
    "            # Add the log-intensity term\n",
    "            log_like += lam_ik_arr[:-1].log().sum()\n",
    "            # Subtract the integral term\n",
    "            log_like -= lam_ik_arr[0] * self.events[i][0]\n",
    "            log_like -= torch.sum(lam_ik_arr[1:] * (self.events[i][1:] - self.events[i][:-1]))\n",
    "        return log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- x0:\n",
      "alpha0: tensor([ 0.0139,  0.1437,  0.0419,  0.0163,  0.2082,  0.1733,  0.2367, -0.0714,\n",
      "         0.2616, -0.0619,  0.1693,  0.0550, -0.0112,  0.1900,  0.2501,  0.1661,\n",
      "         0.1042, -0.0594, -0.0040,  0.0496,  0.2440,  0.1317,  0.1629,  0.0191])\n",
      "beta0: tensor([-0.5277, -0.9773, -0.9235, -0.4631, -0.8242, -0.5354, -0.6876, -0.4724,\n",
      "        -0.6690, -0.8541, -0.8499, -0.4657, -0.6525, -0.8175, -1.0829, -0.5997,\n",
      "        -0.9495, -0.7275, -0.4740, -0.9010, -0.7506, -0.6385, -0.8468, -0.5551])\n",
      "\n",
      "iter: 10000 | dx: 4.1485e-04 | loss: 1.3021e+05    "
     ]
    }
   ],
   "source": [
    "from tsvar.wold_model import WoldModel\n",
    "from tsvar.models import ModelVariational\n",
    "from tsvar.priors import GaussianLaplacianPrior\n",
    "from tsvar.posteriors import LogNormalPosterior\n",
    "from tsvar.learners import VariationalInferenceLearner\n",
    "\n",
    "# model_wold = WoldModelSimple()\n",
    "# model_wold.set_beta(beta)\n",
    "# n_params = len(mu) + len(A.flatten())\n",
    "\n",
    "model_wold = WoldModel()\n",
    "n_params = len(mu) + len(beta) + len(alpha.flatten())\n",
    "\n",
    "model_var = ModelVariational(\n",
    "    model=model_wold,\n",
    "    prior=GaussianLaplacianPrior(\n",
    "        C=torch.ones(n_params, dtype=torch.float) * 100.0,\n",
    "        mask_gaus=torch.cat((\n",
    "            torch.ones(2 * dim, dtype=torch.bool),\n",
    "            torch.zeros(dim * dim, dtype=torch.bool)\n",
    "        ))\n",
    "    ),\n",
    "    posterior=LogNormalPosterior(),\n",
    "    n_samples=1,\n",
    ")\n",
    "\n",
    "coeffs_true = torch.cat((mu, beta, alpha.flatten()))\n",
    "\n",
    "x0 = torch.tensor(np.hstack((\n",
    "    np.random.normal(loc=0.1, scale=0.1, size=dim),\n",
    "    np.random.normal(loc=0.1, scale=0.1, size=dim),\n",
    "    np.random.normal(loc=0.1, scale=0.1, size=dim*dim),\n",
    "    \n",
    "    np.log(np.random.normal(loc=0.5, scale=0.1, size=dim)),\n",
    "    np.log(np.random.normal(loc=0.5, scale=0.1, size=dim)),\n",
    "    np.log(np.random.normal(loc=0.5, scale=0.1, size=dim*dim)),\n",
    ")), dtype=torch.float)\n",
    "\n",
    "print('--------- x0:')\n",
    "print('alpha0:', x0[:n_params])\n",
    "print('beta0:', x0[n_params:])\n",
    "print()\n",
    "\n",
    "optimizer = torch.optim.Adagrad([x0])\n",
    "\n",
    "learner_callback = tsvar.utils.callbacks.LearnerCallbackMLE(x0, coeffs_true.numpy(), print_every=100)\n",
    "\n",
    "learner = VariationalInferenceLearner(\n",
    "    model=model_var, optimizer=optimizer, lr=0.1,\n",
    "    tol=1e-6, \n",
    "    lr_gamma=0.9999, max_iter=10000,\n",
    "    hyperparam_interval=1000, hyperparam_offset=np.inf, hyperparam_momentum=0.0,\n",
    ")\n",
    "\n",
    "coeffs_hat = learner.fit(events, end_time, x0, callback=learner_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0139,  0.1437,  0.0419,  0.0163,  0.2082,  0.1733,  0.2367, -0.0714,\n",
       "         0.2616, -0.0619,  0.1693,  0.0550, -0.0112,  0.1900,  0.2501,  0.1661,\n",
       "         0.1042, -0.0594, -0.0040,  0.0496,  0.2440,  0.1317,  0.1629,  0.0191])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0[:n_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5277, -0.9773, -0.9235, -0.4631, -0.8242, -0.5354, -0.6876, -0.4724,\n",
       "        -0.6690, -0.8541, -0.8499, -0.4657, -0.6525, -0.8175, -1.0829, -0.5997,\n",
       "        -0.9495, -0.7275, -0.4740, -0.9010, -0.7506, -0.6385, -0.8468, -0.5551])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0[n_params:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.  , -2.34, -2.14, -2.76, -0.17,  2.35,  0.78, -0.39, -0.5 , -0.43, -1.96, -2.72, -2.36, -1.78, -0.73, -1.78, -2.68, -2.13, -1.62, -0.18, -2.88, -0.13,  0.09, -2.24], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_hat[:n_params].detach().numpy().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6848, -1.8944, -2.2691, -1.6920, -1.6952, -1.0753, -1.6184, -1.8310,\n",
       "        -2.3093, -2.1432, -1.5985, -1.5317, -1.2948, -1.2958, -1.2857, -1.2465,\n",
       "        -1.4505, -1.2699, -1.2314, -2.3126, -1.4948, -2.3944, -2.7767, -1.4000],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_hat[n_params:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.1 , 0.05, 0.01, 1.5 , 1.5 , 1.  , 1.  , 0.7 , 0.7 , 0.  , 0.  , 0.  , 0.  , 0.7 , 0.  , 0.  , 0.  , 0.  , 0.7 , 0.  , 0.7 , 0.7 , 0.  ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_true.detach().numpy().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coeffs_hat_mode = learner.model.posterior.mode(coeffs_hat[:n_params], coeffs_hat[n_params:]).detach().numpy().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6 , 0.64, 0.13, 0.06],\n",
       "       [0.09, 0.16, 0.45, 0.16],\n",
       "       [0.06, 0.11, 0.18, 0.83],\n",
       "       [0.05, 0.87, 1.09, 0.1 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(coeffs_hat_mode[2*dim:], (dim, dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7000, 0.7000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.7000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.7000],\n",
       "        [0.0000, 0.7000, 0.7000, 0.0000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05,  0.1 ,  0.12,  0.06,  0.86, 11.14,  2.23,  0.69,  0.61,  0.66,  0.14,  0.07,  0.1 ,  0.18,  0.5 ,  0.18,  0.07,  0.12,  0.21,  0.84,  0.06,  0.88,  1.09,  0.11], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model.posterior.mean(coeffs_hat[:n_params], coeffs_hat[n_params:]).detach().numpy().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.     , 0.     , 0.     , 0.     , 0.17321, 3.91408, 0.44721, 0.1    , 0.     , 0.1    , 0.     , 0.     , 0.     , 0.     , 0.14142, 0.     , 0.     , 0.     , 0.     , 0.1    , 0.     , 0.1    , 0.     , 0.     ], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(learner.model.posterior.variance(coeffs_hat[:n_params], coeffs_hat[n_params:]).detach().numpy().round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
