{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test algorithms on a synthetic realization of a multivariate Wold process\n",
    "\n",
    "In this notebook, we run all the algorithms described on the paper on a synthetic realization of a multivariate Wold process. Specifically, the algorithms are:\n",
    "\n",
    "* `WoldModelVariational`: The VI approach introduced in the paper (denoted VI in the paper).\n",
    "* `WoldModelBBVI`: Black-box VI (denoted BBVI in the paper).\n",
    "* `GrangerBusca`: The Granger-Busca approach (denoted GB in the paper).\n",
    "* `WoldModelMLE`: Maximum-Likelihood estimation (denoted MLE in the paper).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries of interest for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Import models\n",
    "import lib\n",
    "from lib.models import WoldModelVariational, WoldModelBBVI, WoldModelMLE\n",
    "from gb import GrangerBusca\n",
    "\n",
    "# Set numpy print format\n",
    "np.set_printoptions(precision=2, floatmode='fixed', sign=' ')\n",
    "\n",
    "# Set larger cells for nicer output\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed for all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.randint(2**32-1)\n",
    "gen_seed = 1234567\n",
    "sim_seed = 8765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Generate toy example dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of dimensions\n",
    "dim = 10\n",
    "# Number of events to simulate\n",
    "max_jumps = 10e3 * dim\n",
    "\n",
    "# Generate a set of parameters for the process\n",
    "param_dict = {\n",
    "    'baseline': np.random.uniform(0.0, 0.05, size=dim),\n",
    "    'adjacency': (np.random.uniform(0.1, 0.2, size=(dim, dim)) \n",
    "                  * np.random.binomial(n=1, p=2*np.log(dim)/dim, size=(dim, dim))),\n",
    "    'beta': np.random.uniform(0.0, 1.0, size=(dim, dim))\n",
    "}\n",
    "\n",
    "print('Baseline:')\n",
    "print(param_dict['baseline'].round(2))\n",
    "print('Alpha:')\n",
    "print(param_dict['adjacency'].round(2))\n",
    "print('Beta:')\n",
    "print(param_dict['beta'].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate a realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('  - Simulate a realization...')\n",
    "wold_sim = lib.simulate.MultivariateWoldSimulator(**param_dict)\n",
    "events = wold_sim.simulate(max_jumps=max_jumps, seed=sim_seed)\n",
    "end_time = max(map(max, events))\n",
    "print((f\"    - Simulated {sum(map(len, events)):,d} events \"\n",
    "       f\"with end time: {end_time:.2f}\"))\n",
    "print(\"    - Events:\")\n",
    "for i, events_i in enumerate(events):\n",
    "    print(f\"      - dim {i:>2d} ({len(events_i):>5d} events):\", events_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Run inference algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run VI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters of the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = len(events)\n",
    "# Set model\n",
    "vi_model = WoldModelVariational(verbose=True)\n",
    "vi_model.observe(events)\n",
    "# Set priors\n",
    "# prior: Alpha\n",
    "as_pr = 0.1 * np.ones((dim + 1, dim))\n",
    "ar_pr = 1.0 * np.ones((dim + 1, dim))\n",
    "# prior: Beta\n",
    "bs_pr = 10.0 * np.ones((dim, dim))\n",
    "br_pr = 10.0 * np.ones((dim, dim))\n",
    "# prior: Z\n",
    "zc_pr = [1.0 * np.ones((len(events[i]), dim+1)) for i in range(dim)]\n",
    "# Set callback (to monitor evolution of iterations)\n",
    "callback = lib.utils.callbacks.Callback(x0=(as_pr / ar_pr)[1:, :].flatten(), print_every=10, dim=dim)\n",
    "# Fit model\n",
    "conv = vi_model.fit(as_pr=as_pr, ar_pr=ar_pr, bs_pr=bs_pr, br_pr=br_pr,\n",
    "                    zc_pr=zc_pr, max_iter=20000, tol=1e-4,\n",
    "                    callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Model:', type(vi_model).__name__)\n",
    "\n",
    "# Mean of posterior\n",
    "vi_coeffs_mean = vi_model.alpha_posterior_mean()\n",
    "vi_base_mean = vi_coeffs_mean[0,:]\n",
    "vi_adj_mean = vi_coeffs_mean[1:,:]\n",
    "\n",
    "print('\\nBaseline:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(param_dict['baseline'])\n",
    "print('Estimated:')\n",
    "print(vi_base_mean)\n",
    "\n",
    "print('\\nAdjacency:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(param_dict['adjacency'])\n",
    "print('Estimated:')\n",
    "print(vi_adj_mean)\n",
    "\n",
    "print('\\nMetrics:')\n",
    "print('---------')\n",
    "fsc = lib.utils.metrics.fscore(vi_adj_mean.flatten(), param_dict['adjacency'].flatten(), threshold=0.05)\n",
    "print(f'F1-Score: {fsc:.2f}')\n",
    "relerr = lib.utils.metrics.relerr(vi_adj_mean.flatten(), param_dict['adjacency'].flatten())\n",
    "print(f'Relative Error: {relerr:.2f}')\n",
    "precAt10 = lib.utils.metrics.precision_at_n(vi_adj_mean.flatten(), param_dict['adjacency'].flatten(), n=10)\n",
    "print(f'Precision@10: {precAt10:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Define model\n",
    "granger_model = GrangerBusca(\n",
    "    alpha_prior=1.0/len(events),\n",
    "    num_iter=3000,\n",
    "    metropolis=True,\n",
    "    beta_strategy='busca',\n",
    "    num_jobs=1,\n",
    ")\n",
    "granger_model.fit(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Model:', type(granger_model).__name__)\n",
    "\n",
    "# Extract infered adjacency from the model\n",
    "gb_adj_hat = granger_model.Alpha_.toarray()\n",
    "gb_adj_hat = gb_adj_hat / gb_adj_hat.sum(axis=1)\n",
    "\n",
    "print('\\nBaseline:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(param_dict['baseline'])\n",
    "print('Estimated:')\n",
    "print(granger_model.mu_)\n",
    "\n",
    "print('\\nAdjacency:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(param_dict['adjacency'])\n",
    "print('Estimated:')\n",
    "print(gb_adj_hat)\n",
    "\n",
    "print('\\nMetrics:')\n",
    "print('---------')\n",
    "fsc = lib.utils.metrics.fscore(gb_adj_hat.flatten(), param_dict['adjacency'].flatten(), threshold=0.05)\n",
    "print(f'F1-Score: {fsc:.2f}')\n",
    "relerr = lib.utils.metrics.relerr(gb_adj_hat.flatten(), param_dict['adjacency'].flatten())\n",
    "print(f'Relative Error: {relerr:.2f}')\n",
    "precAt10 = lib.utils.metrics.precision_at_n(gb_adj_hat.flatten(), param_dict['adjacency'].flatten(), n=10)\n",
    "print(f'Precision@10: {precAt10:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run BBVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set initial point\n",
    "coeffs_start = torch.tensor(np.hstack((\n",
    "    # loc\n",
    "    -2.0 * torch.ones(dim, dtype=torch.float),                  # baseline\n",
    "    0.0 * torch.ones((dim, dim), dtype=torch.float).flatten(),  # beta\n",
    "    0.0 * torch.ones((dim, dim), dtype=torch.float).flatten(),  # adjacency\n",
    "    # scale\n",
    "    torch.log(0.2 * torch.ones(dim, dtype=torch.float)),\n",
    "    torch.log(0.2 * torch.ones((dim, dim), dtype=torch.float).flatten()),\n",
    "    torch.log(0.2 * torch.ones((dim, dim), dtype=torch.float).flatten()),\n",
    ")))\n",
    "\n",
    "# Define priors/posteriors\n",
    "posterior = lib.posteriors.LogNormalPosterior\n",
    "prior = lib.priors.GaussianLaplacianPrior\n",
    "mask_gaus = torch.zeros(dim + dim**2 + dim**2, dtype=torch.bool)\n",
    "mask_gaus[:dim + dim**2] = 1  # Gaussian prior for baseline and beta\n",
    "C = 1e3\n",
    "\n",
    "# Init the model object\n",
    "bbvi_model = WoldModelBBVI(posterior=posterior, prior=prior, C=C,\n",
    "                      prior_kwargs={'mask_gaus': mask_gaus},\n",
    "                      n_samples=1, n_weights=1, weight_temp=1,\n",
    "                      verbose=False, device='cpu')\n",
    "bbvi_model.observe(events, end_time)\n",
    "\n",
    "# Set the callback\n",
    "callback = lib.utils.callbacks.Callback(x0=coeffs_start, print_every=10, dim=dim)\n",
    "\n",
    "# Fit the model\n",
    "conv = bbvi_model.fit(x0=coeffs_start, optimizer=torch.optim.Adam, lr=0.1,\n",
    "                      lr_sched=0.9999, tol=1e-4, max_iter=20000,\n",
    "                      mstep_interval=100, mstep_offset=500, mstep_momentum=0.5,\n",
    "                      seed=None, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model:', type(bbvi_model).__name__)\n",
    "\n",
    "# Extract infered adjacency from the model\n",
    "bbvi_coeffs_mean = bbvi_model.posterior.mean(bbvi_model.coeffs[:bbvi_model.n_params],\n",
    "                                             bbvi_model.coeffs[bbvi_model.n_params:]).detach().numpy()\n",
    "\n",
    "bbvi_base_mean = bbvi_coeffs_mean[:dim]\n",
    "bbvi_adj_mean = bbvi_coeffs_mean[-dim**2:]\n",
    "\n",
    "print('Baseline:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(param_dict['baseline'])\n",
    "print('Estimated:')\n",
    "print(bbvi_base_mean)\n",
    "print()\n",
    "\n",
    "print('Adjacency:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(param_dict['adjacency'])\n",
    "print('Estimated:')\n",
    "print(bbvi_adj_mean)\n",
    "\n",
    "print()\n",
    "print('Metrics:')\n",
    "print('---------')\n",
    "fsc = lib.utils.metrics.fscore(bbvi_adj_mean.flatten(), param_dict['adjacency'].flatten(), threshold=0.05)\n",
    "print(f'F1-Score: {fsc:.2f}')\n",
    "relerr = lib.utils.metrics.relerr(bbvi_adj_mean.flatten(), param_dict['adjacency'].flatten())\n",
    "print(f'Relative Error: {relerr:.2f}')\n",
    "precAt10 = lib.utils.metrics.precision_at_n(bbvi_adj_mean.flatten(), param_dict['adjacency'].flatten(), n=10)\n",
    "print(f'Precision@10: {precAt10:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set initial point\n",
    "coeffs_start = torch.tensor(np.hstack((\n",
    "    np.random.uniform(0.0, 1.0, size=dim),     # baseline\n",
    "    np.random.uniform(0.0, 1.0, size=dim**2),  # beta\n",
    "    np.random.uniform(0.0, 1.0, size=dim**2)   # adjacency\n",
    ")))\n",
    "\n",
    "# Define model\n",
    "mle_model = WoldModelMLE(verbose=True)\n",
    "mle_model.observe(events, end_time)\n",
    "\n",
    "# Set callback (to monitor algorithm)\n",
    "callback = lib.utils.callbacks.Callback(coeffs_start, print_every=10, dim=dim)\n",
    "\n",
    "# Fit model\n",
    "conv = mle_model.fit(x0=coeffs_start, optimizer=torch.optim.Adam, lr=0.1,\n",
    "                     lr_sched=0.9999, tol=1e-4, max_iter=20000,\n",
    "                     penalty=lib.priors.GaussianPrior, C=1e10,\n",
    "                     seed=None, callback=callback)\n",
    "mle_coeffs_hat = mle_model.coeffs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model:', type(mle_model).__name__)\n",
    "\n",
    "# Extract infered adjacency from the model\n",
    "mle_coeffs_hat = mle_model.coeffs.detach().numpy()\n",
    "mle_base_hat = mle_coeffs_hat[:dim]\n",
    "mle_alpha_hat = np.reshape(mle_coeffs_hat[dim+dim**2:], (dim, dim))\n",
    "\n",
    "print('Baseline:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(param_dict['baseline'])\n",
    "print('Estimated:')\n",
    "print(mle_base_hat)\n",
    "print()\n",
    "\n",
    "print('Adjacency:')\n",
    "print('---------')\n",
    "print('Ground truth:')\n",
    "print(param_dict['adjacency'])\n",
    "print('Estimated:')\n",
    "print(mle_alpha_hat)\n",
    "\n",
    "print()\n",
    "print('Metrics:')\n",
    "print('---------')\n",
    "fsc = lib.utils.metrics.fscore(mle_alpha_hat.flatten(), param_dict['adjacency'].flatten(), threshold=0.05)\n",
    "print(f'F1-Score: {fsc:.2f}')\n",
    "relerr = lib.utils.metrics.relerr(mle_alpha_hat.flatten(), param_dict['adjacency'].flatten())\n",
    "print(f'Relative Error: {relerr:.2f}')\n",
    "precAt10 = lib.utils.metrics.precision_at_n(mle_alpha_hat.flatten(), param_dict['adjacency'].flatten(), n=10)\n",
    "print(f'Precision@10: {precAt10:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
