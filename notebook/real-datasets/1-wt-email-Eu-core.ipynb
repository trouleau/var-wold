{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import tsvar\n",
    "from tsvar.preprocessing import Dataset\n",
    "import experiments_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set cells width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load the dataset\n",
    "\n",
    "Set input path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"../../data/email-Eu-core-temporal.txt.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(INPUT_PATH, top=100, timescale='busca')\n",
    "#dataset = Dataset.from_pickle(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x252 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(18, 3.5))\n",
    "\n",
    "axs[0].hist(list(map(len, dataset.timestamps)))\n",
    "axs[0].set_xlabel('Number of events \\n in each dim')\n",
    "\n",
    "end_time = dataset.end_time\n",
    "axs[1].hist(list(map(min, dataset.timestamps)), bins=np.linspace(0, end_time, 20))\n",
    "axs[1].set_xlabel('First of event \\n in each dim')\n",
    "\n",
    "axs[2].hist(list(map(max, dataset.timestamps)), bins=np.linspace(0, end_time, 20))\n",
    "axs[2].set_xlabel('Last of events \\n in each dim')\n",
    "\n",
    "fig.suptitle(f\"Dataset {os.path.split(INPUT_PATH)[1]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of dimensions: 100\n",
      "    Num. of events: 92,924\n",
      "               %NZ: 26.23%\n",
      "\n",
      "Stats. of num. of events per dim:\n",
      "count     100.000000\n",
      "mean      929.240000\n",
      "std       589.331261\n",
      "min        82.000000\n",
      "25%       544.000000\n",
      "50%       770.000000\n",
      "75%      1210.000000\n",
      "max      3334.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num. of dimensions: {len(dataset.timestamps):,d}\")\n",
    "print(f\"    Num. of events: {sum(map(len, dataset.timestamps)):,d}\")\n",
    "print(f\"               %NZ: {100 * dataset.graph.number_of_edges() / (dataset.graph.number_of_nodes() ** 2):.2f}%\")\n",
    "print()\n",
    "print(\"Stats. of num. of events per dim:\")\n",
    "num_jumps_per_dim = np.array(list(map(len, dataset.timestamps)))\n",
    "print(pd.Series(num_jumps_per_dim).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build ground truth adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_true = nx.adjacency_matrix(dataset.graph, nodelist=range(dataset.dim)).toarray()\n",
    "adjacency_true = adjacency_true / adjacency_true.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diag_mask = np.eye(len(adjacency_true)).astype(bool)\n",
    "plt.boxplot([adjacency_true[~diag_mask & (adjacency_true > 0)], adjacency_true[diag_mask & (adjacency_true > 0)]],\n",
    "            labels=['Non-Diag Edges', 'Self-loops']);\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the scale of time using empirical inter-arrival time distributions\n",
    "\n",
    "Compute this for both definitions $\\{\\beta_j\\}$ and $\\{\\beta_{ij}\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busca estimators of **beta_j**:\n",
      "count    100.000000\n",
      "mean       1.047905\n",
      "std        1.697729\n",
      "min        0.027075\n",
      "25%        0.290726\n",
      "50%        0.556137\n",
      "75%        0.916652\n",
      "max       13.946247\n",
      "dtype: float64\n",
      "\n",
      "Busca estimators of **beta_{ji}**:\n",
      "count    10000.000000\n",
      "mean         1.218551\n",
      "std          2.322353\n",
      "min          0.000000\n",
      "25%          0.344177\n",
      "50%          1.005101\n",
      "75%          1.474181\n",
      "max        118.583466\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 4), sharey=True)\n",
    "\n",
    "busca_betas = np.array([np.median(np.hstack((ev[0], np.diff(ev)))) for ev in dataset.timestamps])\n",
    "plt.sca(axs[0])\n",
    "plt.grid()\n",
    "plt.boxplot(busca_betas, labels=[r'Distribution of Busca estimators of $\\beta_j$']);\n",
    "plt.yscale('log')\n",
    "print('Busca estimators of **beta_j**:')\n",
    "print(pd.Series(busca_betas.flatten()).describe())\n",
    "print()\n",
    "\n",
    "wold_model = tsvar.models.WoldModel()\n",
    "wold_model.observe(dataset.timestamps)\n",
    "busca_beta_ji = np.zeros((wold_model.dim, wold_model.dim))\n",
    "for i in range(wold_model.dim):\n",
    "    busca_beta_ji[:, i] = np.median(wold_model.delta_ikj[i][:, :], axis=0) / np.exp(1)\n",
    "del wold_model\n",
    "plt.sca(axs[1])\n",
    "plt.grid()\n",
    "plt.boxplot(busca_beta_ji.flatten(), labels=[r'Distribution of Busca estimators of $\\beta_{ji}$']);\n",
    "plt.yscale('log')\n",
    "print('Busca estimators of **beta_{ji}**:')\n",
    "print(pd.Series(busca_beta_ji.flatten()).describe())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = dataset.timestamps\n",
    "events = [np.sort(ev) for ev in events]\n",
    "end_time = dataset.end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69911 23013\n"
     ]
    }
   ],
   "source": [
    "t0 = min(map(min, events))\n",
    "t1 = max(map(max, events))\n",
    "\n",
    "train_start = t0\n",
    "train_end = t0 + (t1 - t0) * 0.5\n",
    "test_end = t1 + 1e-5\n",
    "\n",
    "train_events = [ev[(ev >= train_start) & (ev < train_end)] - train_start for ev in events]\n",
    "test_events = [ev[(ev >= train_end) & (ev < test_end)] - train_end for ev in events]\n",
    "\n",
    "print(sum(map(len, train_events)), sum(map(len, test_events)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Run VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHA:\n",
      "------\n",
      "mean\n",
      "1.0\n",
      "variance\n",
      "1.0\n",
      "BETA:\n",
      "-----\n",
      "mean\n",
      "1.0101010101010102\n",
      "variance\n",
      "0.010411265822521235\n"
     ]
    }
   ],
   "source": [
    "dim = len(train_events)\n",
    "\n",
    "# Set priors\n",
    "# prior: Alpha\n",
    "as_pr = 1.0 * np.ones((dim + 1, dim))\n",
    "ar_pr = 1.0 * np.ones((dim + 1, dim))\n",
    "\n",
    "# prior: Beta\n",
    "bs_pr = 100.0 * np.ones((dim, dim))\n",
    "br_pr = 100.0 * np.ones((dim, dim))\n",
    "\n",
    "# prior: Z\n",
    "zc_pr = [1.0 * np.ones((len(train_events[i]), dim+1)) for i in range(dim)]\n",
    "\n",
    "print('ALPHA:')\n",
    "print('------')\n",
    "print('mean')\n",
    "print(as_pr[0,0] / ar_pr[0,0])\n",
    "print('variance')\n",
    "print(as_pr[0,0] / ar_pr[0,0] ** 2)\n",
    "\n",
    "print('BETA:')\n",
    "print('-----')\n",
    "print('mean')\n",
    "print(br_pr[0,0] / (bs_pr[0,0] - 1))\n",
    "print('variance')\n",
    "print(br_pr[0,0]**2 / ((bs_pr[0,0] - 1)**2 * (bs_pr[0,0] - 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model & observations\n",
    "vi_model = tsvar.models.WoldModelVariationalOther(verbose=True)\n",
    "vi_model.observe(train_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> sim 0\n",
      "iter:   100 | dx: +1.5899e-03 | f1-score: 0.00 | relerr: 6.36e+00 | p@5: 0.60 | p@10: 0.50 | p@20: 0.30 | time/it: 4.76e-01     \n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 825.00\n",
      "False Positive: 1775.00\n",
      " True Negative: 5602.00\n",
      "False Negative: 1798.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.38\n",
      "Prec@200: 0.40\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12525252525252517\n",
      "10 0.20505050505050498\n",
      "20 0.29797979797979796\n",
      "50 0.33252525252525256\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 1\n",
      "iter:   100 | dx: +1.5899e-03 | f1-score: 0.00 | relerr: 6.36e+00 | p@5: 0.60 | p@10: 0.50 | p@20: 0.30 | time/it: 4.76e-01     \n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 825.00\n",
      "False Positive: 1775.00\n",
      " True Negative: 5602.00\n",
      "False Negative: 1798.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.38\n",
      "Prec@200: 0.40\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12525252525252517\n",
      "10 0.20505050505050498\n",
      "20 0.29797979797979796\n",
      "50 0.33252525252525256\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 2\n",
      "iter:   100 | dx: +1.5899e-03 | f1-score: 0.00 | relerr: 6.36e+00 | p@5: 0.60 | p@10: 0.50 | p@20: 0.30 | time/it: 5.91e-01     \n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 825.00\n",
      "False Positive: 1775.00\n",
      " True Negative: 5602.00\n",
      "False Negative: 1798.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.38\n",
      "Prec@200: 0.40\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12525252525252517\n",
      "10 0.20505050505050498\n",
      "20 0.29797979797979796\n",
      "50 0.33252525252525256\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 3\n",
      "iter:   100 | dx: +1.5899e-03 | f1-score: 0.00 | relerr: 6.36e+00 | p@5: 0.60 | p@10: 0.50 | p@20: 0.30 | time/it: 5.49e-01     \n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 825.00\n",
      "False Positive: 1775.00\n",
      " True Negative: 5602.00\n",
      "False Negative: 1798.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.38\n",
      "Prec@200: 0.40\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12525252525252517\n",
      "10 0.20505050505050498\n",
      "20 0.29797979797979796\n",
      "50 0.33252525252525256\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 4\n",
      "iter:   100 | dx: +1.5899e-03 | f1-score: 0.00 | relerr: 6.36e+00 | p@5: 0.60 | p@10: 0.50 | p@20: 0.30 | time/it: 5.33e-01     \n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 825.00\n",
      "False Positive: 1775.00\n",
      " True Negative: 5602.00\n",
      "False Negative: 1798.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.38\n",
      "Prec@200: 0.40\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12525252525252517\n",
      "10 0.20505050505050498\n",
      "20 0.29797979797979796\n",
      "50 0.33252525252525256\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 5\n",
      "iter:   100 | dx: +1.5899e-03 | f1-score: 0.00 | relerr: 6.36e+00 | p@5: 0.60 | p@10: 0.50 | p@20: 0.30 | time/it: 7.23e-01     \n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 825.00\n",
      "False Positive: 1775.00\n",
      " True Negative: 5602.00\n",
      "False Negative: 1798.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.38\n",
      "Prec@200: 0.40\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12525252525252517\n",
      "10 0.20505050505050498\n",
      "20 0.29797979797979796\n",
      "50 0.33252525252525256\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 6\n",
      "iter:   100 | dx: +1.5899e-03 | f1-score: 0.00 | relerr: 6.36e+00 | p@5: 0.60 | p@10: 0.50 | p@20: 0.30 | time/it: 6.95e-01     \n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 825.00\n",
      "False Positive: 1775.00\n",
      " True Negative: 5602.00\n",
      "False Negative: 1798.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.38\n",
      "Prec@200: 0.40\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12525252525252517\n",
      "10 0.20505050505050498\n",
      "20 0.29797979797979796\n",
      "50 0.33252525252525256\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 7\n",
      "iter:   100 | dx: +1.5899e-03 | f1-score: 0.00 | relerr: 6.36e+00 | p@5: 0.60 | p@10: 0.50 | p@20: 0.30 | time/it: 7.32e-01     \n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 825.00\n",
      "False Positive: 1775.00\n",
      " True Negative: 5602.00\n",
      "False Negative: 1798.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.38\n",
      "Prec@200: 0.40\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12525252525252517\n",
      "10 0.20505050505050498\n",
      "20 0.29797979797979796\n",
      "50 0.33252525252525256\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 8\n",
      "iter:   100 | dx: +1.5899e-03 | f1-score: 0.00 | relerr: 6.36e+00 | p@5: 0.60 | p@10: 0.50 | p@20: 0.30 | time/it: 5.27e-01     \n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 825.00\n",
      "False Positive: 1775.00\n",
      " True Negative: 5602.00\n",
      "False Negative: 1798.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.38\n",
      "Prec@200: 0.40\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12525252525252517\n",
      "10 0.20505050505050498\n",
      "20 0.29797979797979796\n",
      "50 0.33252525252525256\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> sim 9\n",
      "iter:   100 | dx: +1.5899e-03 | f1-score: 0.00 | relerr: 6.36e+00 | p@5: 0.60 | p@10: 0.50 | p@20: 0.30 | time/it: 5.04e-01     \n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 825.00\n",
      "False Positive: 1775.00\n",
      " True Negative: 5602.00\n",
      "False Negative: 1798.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.38\n",
      "Prec@200: 0.40\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12525252525252517\n",
      "10 0.20505050505050498\n",
      "20 0.29797979797979796\n",
      "50 0.33252525252525256\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vi_res_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print('---> sim', i)\n",
    "    \n",
    "    # Set callback (parameters of callback are just the posterior mean of alpha)\n",
    "    callback = tsvar.utils.callbacks.LearnerCallbackMLE(\n",
    "        x0=(as_pr[1:,:] / ar_pr[1:,:]).flatten(), print_every=100,\n",
    "        coeffs_true=adjacency_true.flatten(),\n",
    "        acc_thresh=0.05, dim=dim, \n",
    "        widgets={'f1score', 'relerr', 'prec@5', 'prec@10', 'prec@20'},\n",
    "        default_end='\\n')\n",
    "    \n",
    "    # Fit model\n",
    "    vi_model.fit(as_pr=as_pr, ar_pr=ar_pr, bs_pr=bs_pr, br_pr=br_pr, zc_pr=zc_pr, \n",
    "              max_iter=100, tol=1e-3, callback=callback)\n",
    "    \n",
    "    # Extract adjacency mean\n",
    "    vi_adj_hat = vi_model._as_po[1:, :] / vi_model._ar_po[1:, :]\n",
    "    \n",
    "    # Find suitable threshold for the scale of the data\n",
    "    vi_adj_hat_flat = vi_adj_hat.flatten()\n",
    "    thresh = vi_adj_hat_flat[np.argsort(vi_adj_hat_flat)[::-1][2600]]\n",
    "\n",
    "    vi_res_dict[i] = experiments_utils.print_report(\n",
    "        name=type(vi_model).__name__, adj_hat=vi_adj_hat, adj_true=adjacency_true, thresh=thresh);\n",
    "    vi_res_dict[i]['threshold'] = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>prec@5</th>\n",
       "      <th>prec@10</th>\n",
       "      <th>prec@20</th>\n",
       "      <th>prec@50</th>\n",
       "      <th>prec@100</th>\n",
       "      <th>prec@200</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tnr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.700000e-01</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>5677.0</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.300000e-01</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.206335e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.103168e-17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy  precision  recall  f1score  prec@5  prec@10  prec@20  prec@50  prec@100      prec@200     tp      fp      tn      fn   tpr           fpr   tnr   fnr  threshold\n",
       "mean      0.66       0.35    0.34     0.34     0.4      0.4     0.45      0.4      0.45  4.700000e-01  900.0  1700.0  5677.0  1723.0  0.34  2.300000e-01  0.77  0.66       0.01\n",
       "std       0.00       0.00    0.00     0.00     0.0      0.0     0.00      0.0      0.00  6.206335e-17    0.0     0.0     0.0     0.0  0.00  3.103168e-17  0.00  0.00       0.00"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_res_df = pd.DataFrame(vi_res_dict).T\n",
    "pd.DataFrame([vi_res_df.mean().round(2), vi_res_df.std()], index=['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.941900645504484e-05\n",
      "\n",
      "==================================================\n",
      "========== Method: WoldModelVariationalOther\n",
      "\n",
      "Accuracy: 0.59\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2600.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 570.00\n",
      "False Positive: 2030.00\n",
      " True Negative: 5347.00\n",
      "False Negative: 2053.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.22\n",
      "False Positive Rate: 0.28\n",
      " True Negative Rate: 0.72\n",
      "False Negative Rate: 0.78\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.22\n",
      "Precision: 0.22\n",
      "   Recall: 0.22\n",
      "   PR-AUC: 0.24\n",
      "  ROC-AUC: 0.43\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.50\n",
      " Prec@50: 0.32\n",
      "Prec@200: 0.38\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.0666666666666667\n",
      "10 0.11919191919191906\n",
      "20 0.19090909090909092\n",
      "50 0.2707070707070706\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mu_hat = vi_model._as_po[0, :] / vi_model._ar_po[0, :]\n",
    "adj_hat = vi_model._as_po[1:, :] / vi_model._ar_po[1:, :]\n",
    "#adj_hat = (vi_model._as_po[1:, :] >= 1) * (vi_model._as_po[1:, :] - 1) / vi_model._ar_po[1:, :]\n",
    "beta_hat = vi_model._br_po[:, :] / (vi_model._bs_po[:, :] + 1) + 1\n",
    "model_name = type(vi_model).__name__\n",
    "\n",
    "#adj_hat = adj_hat\n",
    "adj_hat = adj_hat #/ beta_hat\n",
    "\n",
    "#diag_mask = np.eye(adj_hat.shape[0]).astype(bool)\n",
    "#adjacency_true_zero_diag = adjacency_true.copy()\n",
    "#adjacency_true_zero_diag[diag_mask] = 0\n",
    "#adj_hat[diag_mask] = 0\n",
    "\n",
    "vi_adj_hat_flat = adj_hat.flatten()\n",
    "thresh = vi_adj_hat_flat[np.argsort(vi_adj_hat_flat)[::-1][2600]]\n",
    "print(thresh)\n",
    "\n",
    "experiments_utils.print_report(name=type(vi_model).__name__, adj_hat=adj_hat, adj_true=adjacency_true, thresh=thresh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dims = np.array([len(ev) > 0 for ev in test_events])\n",
    "num_test_events = sum(map(len, test_events))\n",
    "test_events_filtered = np.array(test_events)[test_dims].tolist()\n",
    "test_model = tsvar.models.WoldModelOther()\n",
    "test_model.observe(test_events_filtered)\n",
    "\n",
    "def compute_vi_log_likelihoods(vi_model, num_samples=10):\n",
    "    vals = list()\n",
    "    adj_list = list()\n",
    "    for i in range(num_samples):\n",
    "        as_po = vi_model._as_po[np.hstack([[True], test_dims]), :][:, test_dims]\n",
    "        ar_po = vi_model._ar_po[np.hstack([[True], test_dims]), :][:, test_dims]\n",
    "        bs_po = vi_model._bs_po[test_dims, :][:, test_dims]\n",
    "        br_po = vi_model._br_po[test_dims, :][:, test_dims]\n",
    "\n",
    "        alpha_sample = np.random.gamma(shape=as_po, scale=1/ar_po)\n",
    "        beta_sample = np.random.gamma(shape=bs_po, scale=1/br_po)\n",
    "        coeffs = torch.tensor(np.hstack((\n",
    "            alpha_sample[0, :].flatten(), beta_sample.flatten(), alpha_sample[1:, :].flatten()\n",
    "        )))\n",
    "        ll = test_model.log_likelihood(coeffs) / num_test_events\n",
    "        vals.append(ll)\n",
    "        adj_list.append(np.random.gamma(shape=vi_model._as_po, scale=1/vi_model._ar_po)[1:, :])\n",
    "    print(f\"{np.mean(vals):.2f} ($\\pm {np.std(vals):.2e}$)\")\n",
    "    return vals, adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.49 ($\\pm 4.85e-03$)\n"
     ]
    }
   ],
   "source": [
    "vals, vi_adj_list = compute_vi_log_likelihoods(vi_model, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Run GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 10.0\n",
      "---> sim 0\n",
      "\n",
      "==================================================\n",
      "========== Method: GrangerBusca\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2595.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 828.00\n",
      "False Positive: 1767.00\n",
      " True Negative: 5610.00\n",
      "False Negative: 1795.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.32\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.68\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.32\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.20\n",
      " Prec@50: 0.32\n",
      "Prec@200: 0.38\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.11313131313131308\n",
      "10 0.18888888888888877\n",
      "20 0.2681818181818182\n",
      "50 0.3432323232323231\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 1\n",
      "\n",
      "==================================================\n",
      "========== Method: GrangerBusca\n",
      "\n",
      "Accuracy: 0.65\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2599.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 841.00\n",
      "False Positive: 1758.00\n",
      " True Negative: 5619.00\n",
      "False Negative: 1782.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.32\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.68\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.32\n",
      "   PR-AUC: 0.32\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.20\n",
      " Prec@50: 0.34\n",
      "Prec@200: 0.45\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.11919191919191914\n",
      "10 0.1878787878787878\n",
      "20 0.2772727272727274\n",
      "50 0.34585858585858564\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 2\n",
      "\n",
      "==================================================\n",
      "========== Method: GrangerBusca\n",
      "\n",
      "Accuracy: 0.64\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2596.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 817.00\n",
      "False Positive: 1779.00\n",
      " True Negative: 5598.00\n",
      "False Negative: 1806.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.31\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.69\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.31\n",
      "Precision: 0.31\n",
      "   Recall: 0.31\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.56\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.20\n",
      " Prec@50: 0.32\n",
      "Prec@200: 0.43\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.103030303030303\n",
      "10 0.17878787878787863\n",
      "20 0.2828282828282829\n",
      "50 0.34505050505050494\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 3\n",
      "\n",
      "==================================================\n",
      "========== Method: GrangerBusca\n",
      "\n",
      "Accuracy: 0.65\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2594.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 843.00\n",
      "False Positive: 1751.00\n",
      " True Negative: 5626.00\n",
      "False Negative: 1780.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.32\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.68\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.32\n",
      "   PR-AUC: 0.31\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.20\n",
      " Prec@50: 0.34\n",
      "Prec@200: 0.49\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.11515151515151509\n",
      "10 0.19393939393939397\n",
      "20 0.2696969696969697\n",
      "50 0.3472727272727272\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n",
      "---> sim 4\n",
      "\n",
      "==================================================\n",
      "========== Method: GrangerBusca\n",
      "\n",
      "Accuracy: 0.65\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 2599.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 836.00\n",
      "False Positive: 1763.00\n",
      " True Negative: 5614.00\n",
      "False Negative: 1787.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.32\n",
      "False Positive Rate: 0.24\n",
      " True Negative Rate: 0.76\n",
      "False Negative Rate: 0.68\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.32\n",
      "Precision: 0.32\n",
      "   Recall: 0.32\n",
      "   PR-AUC: 0.32\n",
      "  ROC-AUC: 0.57\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.20\n",
      " Prec@50: 0.36\n",
      "Prec@200: 0.45\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.12929292929292918\n",
      "10 0.1989898989898989\n",
      "20 0.27878787878787875\n",
      "50 0.34484848484848485\n",
      "100 0.26494949494949493\n",
      "200 0.13247474747474747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gb\n",
    "import time\n",
    "\n",
    "dim = len(train_events)\n",
    "\n",
    "gb_res_list = list()\n",
    "\n",
    "for dir_prior in [10.0]:\n",
    "    print('='*10, dir_prior)\n",
    "\n",
    "    for i in range(5):\n",
    "        print('---> sim', i)\n",
    "\n",
    "        # Define model\n",
    "        granger_model = gb.GrangerBusca(\n",
    "            alpha_prior=dir_prior,\n",
    "            num_iter=3000,\n",
    "            metropolis=True,\n",
    "            beta_strategy='busca',\n",
    "            num_jobs=4,\n",
    "        )\n",
    "        granger_model.fit(train_events)\n",
    "\n",
    "        # Extract adjacency\n",
    "        gb_adj_hat = granger_model.Alpha_.toarray()\n",
    "        gb_adj_hat = gb_adj_hat / gb_adj_hat.sum(axis=1)[:, None]\n",
    "\n",
    "            # Find suitable threshold for the scale of the data\n",
    "        gb_adj_hat_flat = gb_adj_hat.flatten()\n",
    "        thresh = gb_adj_hat_flat[np.argsort(gb_adj_hat_flat)[::-1][2600]]\n",
    "\n",
    "        gb_res_dict = experiments_utils.print_report(\n",
    "            name=type(granger_model).__name__, adj_hat=gb_adj_hat, adj_true=adjacency_true, thresh=thresh);\n",
    "        gb_res_dict['threshold'] = thresh\n",
    "        gb_res_dict['prior'] = dir_prior\n",
    "        gb_res_list.append(gb_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">prec@10</th>\n",
       "      <th colspan=\"2\" halign=\"left\">prec@50</th>\n",
       "      <th colspan=\"2\" halign=\"left\">prec@200</th>\n",
       "      <th colspan=\"2\" halign=\"left\">pr_auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prior</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1score      prec@10      prec@50       prec@200       pr_auc       \\\n",
       "         mean  std    mean  std    mean   std     mean   std   mean  std   \n",
       "prior                                                                      \n",
       "10.0     0.32  0.0     0.2  0.0    0.34  0.02     0.44  0.04   0.32  0.0   \n",
       "\n",
       "      roc_auc       \n",
       "         mean  std  \n",
       "prior               \n",
       "10.0     0.57  0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_res_df = pd.DataFrame(gb_res_list)\n",
    "gb_res_df.groupby('prior').agg(['mean', 'std'])[['f1score', 'prec@10', 'prec@50', 'prec@200', 'pr_auc', 'roc_auc']].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">prec@10</th>\n",
       "      <th colspan=\"2\" halign=\"left\">prec@50</th>\n",
       "      <th colspan=\"2\" halign=\"left\">prec@200</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prior</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.00</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f1score       prec@10       prec@50       prec@200      \n",
       "           mean   std    mean   std    mean   std     mean   std\n",
       "prior                                                           \n",
       "0.01       0.09  0.00    0.06  0.05    0.04  0.01     0.27  0.02\n",
       "0.10       0.26  0.01    0.10  0.00    0.04  0.01     0.29  0.03\n",
       "1.00       0.32  0.01    0.20  0.00    0.04  0.00     0.29  0.03\n",
       "10.00      0.32  0.01    0.20  0.00    0.35  0.07     0.43  0.03\n",
       "100.00     0.30  0.01    0.28  0.08    0.36  0.03     0.33  0.02\n",
       "1000.00    0.29  0.00    0.38  0.13    0.23  0.05     0.24  0.03"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_res_df = pd.DataFrame(gb_res_list)\n",
    "gb_res_df.groupby('prior').agg(['mean', 'std'])[['f1score', 'prec@10', 'prec@50', 'prec@200', 'pr_auc', 'roc_auc']].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "========== Method: GrangerBusca\n",
      "\n",
      "Accuracy: 0.26\n",
      "\n",
      "Edge counts\n",
      "------------\n",
      "Pred: 509.00\n",
      "True: 2623.00\n",
      "\n",
      "Error counts\n",
      "------------\n",
      " True Positive: 156.00\n",
      "False Positive: 353.00\n",
      " True Negative: 7024.00\n",
      "False Negative: 2467.00\n",
      "\n",
      "Error rates\n",
      "-----------\n",
      " True Positive Rate: 0.06\n",
      "False Positive Rate: 0.05\n",
      " True Negative Rate: 0.95\n",
      "False Negative Rate: 0.94\n",
      "\n",
      "F-Score\n",
      "-------\n",
      " F1-Score: 0.10\n",
      "Precision: 0.31\n",
      "   Recall: 0.06\n",
      "\n",
      "Precision@k\n",
      "-----------\n",
      " Prec@10: 0.10\n",
      " Prec@50: 0.04\n",
      "Prec@200: 0.29\n",
      "\n",
      "Average Precision@k per node\n",
      "----------------------------\n",
      "AvgPrec@k per node:\n",
      "5 0.25656565656565633\n",
      "10 0.2717171717171716\n",
      "20 0.19292929292929295\n",
      "50 0.0999999999999999\n",
      "100 0.05030303030303025\n",
      "200 0.025151515151515126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract infered adjacency\n",
    "adj_hat = granger_model.Alpha_.toarray()\n",
    "adj_hat = adj_hat / adj_hat.sum(axis=1)[:, None]\n",
    "beta_hat = np.ones((dim, dim)) * (granger_model.beta_ + 1)\n",
    "coeffs_hat = np.hstack((granger_model.mu_, beta_hat.flatten(),\n",
    "                        adj_hat.flatten()))\n",
    "model_name = type(granger_model).__name__\n",
    "\n",
    "adj_hat = adj_hat #/ beta_hat  # Does not matter\n",
    "\n",
    "diag_mask = np.eye(adj_hat.shape[0]).astype(bool)\n",
    "adjacency_true_zero_diag = adjacency_true.copy()\n",
    "adjacency_true_zero_diag[diag_mask] = 0\n",
    "#adj_hat[diag_mask] = 0\n",
    "\n",
    "\n",
    "THRESH = 0.00  # GB is already sparse\n",
    "\n",
    "experiments_utils.print_report(name=model_name, adj_hat=adj_hat, adj_true=adjacency_true, thresh=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gb\n",
    "\n",
    "test_dims = np.array([len(ev) > 0 for ev in test_events])\n",
    "num_test_events = sum(map(len, test_events))\n",
    "test_events_filtered = np.array(test_events)[test_dims].tolist()\n",
    "test_model = tsvar.models.WoldModelOther()\n",
    "test_model.observe(test_events_filtered)\n",
    "\n",
    "def compute_gb_log_likelihoods(num_samples=10):\n",
    "    vals = list()\n",
    "    for i in range(num_samples):\n",
    "        print(f'\\r{i}', end='')\n",
    "        # Define model\n",
    "        granger_model = gb.GrangerBusca(\n",
    "            alpha_prior=10.00,\n",
    "            num_iter=300,\n",
    "            metropolis=True,\n",
    "            beta_strategy='busca',\n",
    "            num_jobs=10,\n",
    "        )\n",
    "\n",
    "        # Fit the model\n",
    "        granger_model.fit(events)\n",
    "\n",
    "        # Extract estimate of parameters\n",
    "        mu_hat = granger_model.mu_[test_dims]\n",
    "        adj_hat = granger_model.Alpha_.toarray()[test_dims, :][:, test_dims]\n",
    "        adj_hat = adj_hat / adj_hat.sum(axis=1)[:, None]\n",
    "        dim = len(events)\n",
    "        beta_hat = np.ones((dim, dim)) * granger_model.beta_\n",
    "        beta_hat = beta_hat[test_dims, :][:, test_dims]\n",
    "        coeffs_hat = torch.tensor(np.hstack((\n",
    "            mu_hat, beta_hat.flatten(), adj_hat.flatten()\n",
    "        )))\n",
    "        \n",
    "        ll = test_model.log_likelihood(coeffs_hat) / num_test_events\n",
    "        vals.append(ll)\n",
    "    print('\\r', end='')\n",
    "    print(f\"{np.mean(vals):.2f} ($\\pm {np.std(vals):.2e}$)\")\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.31 ($\\pm 8.81e-03$)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(-4.2978, dtype=torch.float64),\n",
       " tensor(-4.3184, dtype=torch.float64),\n",
       " tensor(-4.2967, dtype=torch.float64),\n",
       " tensor(-4.3107, dtype=torch.float64),\n",
       " tensor(-4.3136, dtype=torch.float64),\n",
       " tensor(-4.3168, dtype=torch.float64),\n",
       " tensor(-4.2915, dtype=torch.float64),\n",
       " tensor(-4.3048, dtype=torch.float64),\n",
       " tensor(-4.3144, dtype=torch.float64),\n",
       " tensor(-4.3070, dtype=torch.float64)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gb_log_likelihoods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
